{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89466d94",
   "metadata": {},
   "source": [
    "# Chapter 7: Distributed Training with Ray Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23b3af",
   "metadata": {},
   "source": [
    "\n",
    "You can run this notebook directly in\n",
    "[Colab](https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_07_train.ipynb).\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_07_train.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "The book has been written for Ray 2.2.0,which at the time of writing has not\n",
    "officially been released yet. If you are reading this and this version is already\n",
    "available, you can install it using `pip install ray==2.2.0`. If not, you can\n",
    "use a nightly wheel (here for Python 3.7 on Linux):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f5daa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[31mERROR: ray-3.0.0.dev0-cp37-cp37m-macosx_10_15_intel.whl is not a supported wheel on this platform.\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "! pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-3.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "94e05d4f",
   "metadata": {},
   "source": [
    "Should you not run this notebook in Colab and need another type of wheel, please\n",
    "refer to Ray's [installation instructions for nightlies](https://docs.ray.io/en/latest/ray-overview/installation.html#install-nightlies).\n",
    "\n",
    "For this chapter you will also need to install the following dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1765ed6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting ray[data,train]>=2.1.0\r\n",
      "  Downloading ray-2.1.0-cp39-cp39-macosx_10_15_x86_64.whl (76.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.2/76.2 MB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting dask==2022.2.0\r\n",
      "  Using cached dask-2022.2.0-py3-none-any.whl (1.1 MB)\r\n",
      "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.9/site-packages (1.12.1)\r\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.9/site-packages (from dask==2022.2.0) (2022.8.2)\r\n",
      "Collecting partd>=0.3.10\r\n",
      "  Using cached partd-1.3.0-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.9/site-packages (from dask==2022.2.0) (2.0.0)\r\n",
      "Collecting toolz>=0.8.2\r\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.9/site-packages (from dask==2022.2.0) (5.4.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from dask==2022.2.0) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch==1.12.1) (3.10.0.2)\r\n",
      "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (7.1.2)\r\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (1.43.0)\r\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (20.3.0)\r\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (1.2.0)\r\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (3.2.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (2.25.1)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (3.19.6)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (1.23.3)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (1.0.3)\r\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (1.3.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (3.3.1)\r\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (20.8.1)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (1.4.4)\r\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (2.5.1)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (0.8.9)\r\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=6.0.1 in /usr/local/lib/python3.9/site-packages (from ray[data,train]>=2.1.0) (6.0.1)\r\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.9/site-packages/six-1.15.0-py3.9.egg (from grpcio>=1.32.0->ray[data,train]>=2.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->dask==2022.2.0) (2.4.7)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->ray[data,train]>=2.1.0) (2020.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas->ray[data,train]>=2.1.0) (2.8.1)\r\n",
      "Collecting locket\r\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\r\n",
      "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[data,train]>=2.1.0) (1.1.0)\r\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[data,train]>=2.1.0) (0.3.3)\r\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[data,train]>=2.1.0) (2.4.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[data,train]>=2.1.0) (0.17.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[data,train]>=2.1.0) (59.5.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->ray[data,train]>=2.1.0) (1.26.12)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->ray[data,train]>=2.1.0) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->ray[data,train]>=2.1.0) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests->ray[data,train]>=2.1.0) (4.0.0)\r\n",
      "Installing collected packages: toolz, locket, ray, partd, dask\r\n",
      "\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.0.0\r\n",
      "    Uninstalling ray-2.0.0:\r\n",
      "      Successfully uninstalled ray-2.0.0\r\n",
      "\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mSuccessfully installed dask-2022.2.0 locket-1.0.0 partd-1.3.0 ray-2.1.0 toolz-0.12.0\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: xgboost==1.6.2 in /usr/local/lib/python3.9/site-packages (1.6.2)\r\n",
      "Requirement already satisfied: xgboost-ray>=0.1.10 in /usr/local/lib/python3.9/site-packages (0.1.11)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from xgboost==1.6.2) (1.8.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from xgboost==1.6.2) (1.23.3)\r\n",
      "Requirement already satisfied: ray>=1.10 in /usr/local/lib/python3.9/site-packages (from xgboost-ray>=0.1.10) (2.1.0)\r\n",
      "Requirement already satisfied: wrapt>=1.12.1 in /usr/local/lib/python3.9/site-packages (from xgboost-ray>=0.1.10) (1.12.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from xgboost-ray>=0.1.10) (21.3)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from xgboost-ray>=0.1.10) (1.4.4)\r\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (20.3.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (2.25.1)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (1.0.3)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (5.4.1)\r\n",
      "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (7.1.2)\r\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (1.3.0)\r\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (20.8.1)\r\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (3.2.0)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (3.19.6)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (3.3.1)\r\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (1.43.0)\r\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.9/site-packages (from ray>=1.10->xgboost-ray>=0.1.10) (1.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->xgboost-ray>=0.1.10) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas->xgboost-ray>=0.1.10) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->xgboost-ray>=0.1.10) (2020.4)\r\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.9/site-packages/six-1.15.0-py3.9.egg (from grpcio>=1.32.0->ray>=1.10->xgboost-ray>=0.1.10) (1.15.0)\r\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost-ray>=0.1.10) (2.4.0)\r\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost-ray>=0.1.10) (0.3.3)\r\n",
      "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost-ray>=0.1.10) (1.1.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray>=1.10->xgboost-ray>=0.1.10) (0.17.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from jsonschema->ray>=1.10->xgboost-ray>=0.1.10) (59.5.0)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests->ray>=1.10->xgboost-ray>=0.1.10) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->ray>=1.10->xgboost-ray>=0.1.10) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->ray>=1.10->xgboost-ray>=0.1.10) (2.10)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->ray>=1.10->xgboost-ray>=0.1.10) (1.26.12)\r\n",
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "! pip install \"ray[data,train]>=2.1.0\" \"dask==2022.2.0\" \"torch==1.12.1\"\n",
    "! pip install \"xgboost==1.6.2\" \"xgboost-ray>=0.1.10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef63a5",
   "metadata": {},
   "source": [
    "\n",
    "To import utility files for this chapter, on Colab you will also have to clone\n",
    "the repo and copy the code files to the base path of the runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a179146",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/maxpumperla/learning_ray\n",
    "%cp -r learning_ray/notebooks/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409cb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.util.dask import enable_dask_on_ray\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "LABEL_COLUMN = \"is_big_tip\"\n",
    "FEATURE_COLUMNS = [\"passenger_count\", \"trip_distance\", \"fare_amount\",\n",
    "                   \"trip_duration\", \"hour\", \"day_of_week\"]\n",
    "\n",
    "enable_dask_on_ray()\n",
    "\n",
    "\n",
    "def load_dataset(path: str, *, include_label=True):\n",
    "    columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"tip_amount\",\n",
    "               \"passenger_count\", \"trip_distance\", \"fare_amount\"]\n",
    "    df = dd.read_parquet(path, columns=columns)\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df[(df[\"passenger_count\"] <= 4) &\n",
    "            (df[\"trip_distance\"] < 100) &\n",
    "            (df[\"fare_amount\"] < 1000)]\n",
    "\n",
    "    df[\"tpep_pickup_datetime\"] = dd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "    df[\"tpep_dropoff_datetime\"] = dd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "\n",
    "    df[\"trip_duration\"] = (df[\"tpep_dropoff_datetime\"] -\n",
    "                           df[\"tpep_pickup_datetime\"]).dt.seconds\n",
    "    df = df[df[\"trip_duration\"] < 4 * 60 * 60] # 4 hours.\n",
    "    df[\"hour\"] = df[\"tpep_pickup_datetime\"].dt.hour\n",
    "    df[\"day_of_week\"] = df[\"tpep_pickup_datetime\"].dt.weekday\n",
    "\n",
    "    if include_label:\n",
    "        df[LABEL_COLUMN] = df[\"tip_amount\"] > 0.2 * df[\"fare_amount\"]\n",
    "\n",
    "    df = df.drop(\n",
    "        columns=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"tip_amount\"]\n",
    "    )\n",
    "\n",
    "    return ray.data.from_dask(df).repartition(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91e9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FarePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(6, 256)\n",
    "        self.fc2 = nn.Linear(256, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd15858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import session\n",
    "from ray.air.config import ScalingConfig\n",
    "import ray.train as train\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config: dict):\n",
    "    batch_size = config.get(\"batch_size\", 32)\n",
    "    lr = config.get(\"lr\", 1e-2)\n",
    "    num_epochs = config.get(\"num_epochs\", 3)\n",
    "\n",
    "    dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    model = FarePredictor()\n",
    "    dist_model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_function = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(dist_model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = 0\n",
    "        num_batches = 0\n",
    "        for batch in dataset_shard.iter_torch_batches(\n",
    "                batch_size=batch_size, dtypes=torch.float\n",
    "        ):\n",
    "            labels = torch.unsqueeze(batch[LABEL_COLUMN], dim=1)\n",
    "            inputs = torch.cat(\n",
    "                [torch.unsqueeze(batch[f], dim=1) for f in FEATURE_COLUMNS], dim=1\n",
    "            )\n",
    "            output = dist_model(inputs)\n",
    "            batch_loss = loss_function(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_batches += 1\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "        session.report(\n",
    "            {\"epoch\": epoch, \"loss\": loss},\n",
    "            checkpoint=TorchCheckpoint.from_model(dist_model)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5209607a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 13:58:57,798\tINFO worker.py:1519 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "Repartition: 100%|██████████| 100/100 [00:00<00:00, 107.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14268)\u001B[0m 2022-11-28 13:59:13,024\tINFO config.py:87 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14268)\u001B[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14269)\u001B[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14268)\u001B[0m 2022-11-28 13:59:15,086\tINFO train_loop_utils.py:298 -- Moving model to device: cpu\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14268)\u001B[0m 2022-11-28 13:59:15,088\tINFO train_loop_utils.py:362 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14268)\u001B[0m /usr/local/lib/python3.9/site-packages/ray/air/_internal/torch_utils.py:135: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14268)\u001B[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14269)\u001B[0m /usr/local/lib/python3.9/site-packages/ray/air/_internal/torch_utils.py:135: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001B[2m\u001B[36m(RayTrainWorker pid=14269)\u001B[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name              </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th style=\"text-align: right;\">  epoch</th><th>experiment_id                   </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n</thead>\n<tbody>\n<tr><td>TorchTrainer_7103e_00000</td><td style=\"text-align: right;\">            165.991</td><td style=\"text-align: right;\">  1669640521</td><td style=\"text-align: right;\">                    1</td><td>2022-11-28_14-02-01</td><td>False </td><td>                </td><td style=\"text-align: right;\">      0</td><td>5b072afdc0e748d7b82e1d7dbe312338</td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">5656.2</td><td>127.0.0.1</td><td style=\"text-align: right;\">14259</td><td>True               </td><td style=\"text-align: right;\">              171.36</td><td style=\"text-align: right;\">            171.36</td><td style=\"text-align: right;\">        171.36</td><td style=\"text-align: right;\"> 1669640521</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>7103e_00000</td><td style=\"text-align: right;\">    0.0213518</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 14:09:30,212\tWARNING tune.py:705 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2022-11-28 14:09:30,438\tERROR tune.py:773 -- Trials did not complete: [TorchTrainer_7103e_00000]\n",
      "2022-11-28 14:09:30,439\tINFO tune.py:777 -- Total run time: 624.02 seconds (623.71 seconds for the tuning loop).\n",
      "2022-11-28 14:09:30,440\tWARNING tune.py:783 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Colab does not have enough resources to run this example.\n",
    "# try using num_workers=1, resources_per_worker={\"CPU\": 1, \"GPU\": 0} in your\n",
    "# ScalingConfig below.\n",
    "# In any case, this training loop will take considerable time to run.\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\n",
    "        \"lr\": 1e-2, \"num_epochs\": 3, \"batch_size\": 64\n",
    "    },\n",
    "    scaling_config=ScalingConfig(num_workers=2),\n",
    "    datasets={\n",
    "        \"train\": load_dataset(\"nyc_tlc_data/yellow_tripdata_2020-01.parquet\")\n",
    "    },\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "trained_model = result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88deaa0b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repartition: 100%|██████████| 100/100 [00:00<00:00, 771.81it/s]\n",
      "2022-11-28 14:10:03,685\tINFO dataset.py:3402 -- Created DatasetPipeline with 10 windows: 5.55MiB min, 5.55MiB max, 5.55MiB mean\n",
      "2022-11-28 14:10:03,685\tINFO dataset.py:3412 -- Blocks per window: 10 min, 10 max, 10 mean\n",
      "2022-11-28 14:10:03,687\tWARNING dataset.py:3424 -- ⚠️  This pipeline's parallelism is limited by its blocks per window to ~10 concurrent tasks per window. To maximize performance, increase the blocks per window to at least 12. This may require increasing the base dataset's parallelism and/or adjusting the windowing parameters.\n",
      "2022-11-28 14:10:03,688\tINFO dataset.py:3451 -- ✔️  This pipeline's windows likely fit in object store memory without spilling.\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetPipeline(num_windows=10, num_stages=2)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "\n",
    "batch_predictor = BatchPredictor(trained_model, TorchPredictor)\n",
    "ds = load_dataset(\n",
    "    \"nyc_tlc_data/yellow_tripdata_2021-01.parquet\", include_label=False)\n",
    "\n",
    "batch_predictor.predict_pipelined(ds, blocks_per_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4087d98b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'from_torch' from 'ray.data' (/usr/local/lib/python3.9/site-packages/ray/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/y_/l41py1sx7bl5n30jygrsv0q40000gn/T/ipykernel_14176/917945122.py\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfrom_torch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mnum_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m20\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'from_torch' from 'ray.data' (/usr/local/lib/python3.9/site-packages/ray/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ray.data import from_torch\n",
    "\n",
    "num_samples = 20\n",
    "input_size = 10\n",
    "layer_size = 15\n",
    "output_size = 5\n",
    "num_epochs = 3\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(layer_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_data():\n",
    "    return torch.randn(num_samples, input_size)\n",
    "\n",
    "\n",
    "input_data = train_data()\n",
    "label_data = torch.randn(num_samples, output_size)\n",
    "train_dataset = from_torch(input_data)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    output = model(input_data)\n",
    "    loss = loss_fn(output, label_data)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def training_loop():\n",
    "    model = NeuralNetwork()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf11c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import prepare_model\n",
    "\n",
    "\n",
    "def distributed_training_loop():\n",
    "    model = NeuralNetwork()\n",
    "    model = prepare_model(model)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afbc5a35",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/y_/l41py1sx7bl5n30jygrsv0q40000gn/T/ipykernel_14176/2405101806.py\u001B[0m in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0muse_gpu\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     ),\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0mdatasets\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=distributed_training_loop,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=2,\n",
    "        use_gpu=False\n",
    "    ),\n",
    "    datasets={\"train\": train_dataset}\n",
    ")\n",
    "\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c049af7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray import tune\n",
    "from ray.data.preprocessors import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "dataset = ray.data.from_items(\n",
    "    [{\"X\": x, \"Y\": 1} for x in range(0, 100)] +\n",
    "    [{\"X\": x, \"Y\": 0} for x in range(100, 200)]\n",
    ")\n",
    "prep_v1 = StandardScaler(columns=[\"X\"])\n",
    "prep_v2 = MinMaxScaler(columns=[\"X\"])\n",
    "\n",
    "param_space = {\n",
    "    \"scaling_config\": ScalingConfig(\n",
    "        num_workers=tune.grid_search([2, 4]),\n",
    "        resources_per_worker={\n",
    "            \"CPU\": 2,\n",
    "            \"GPU\": 0,\n",
    "        },\n",
    "    ),\n",
    "    \"preprocessor\": tune.grid_search([prep_v1, prep_v2]),\n",
    "    \"params\": {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"subsample\": tune.uniform(0.5, 1.0),\n",
    "        \"max_depth\": tune.randint(1, 9),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e305d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.air.config import RunConfig\n",
    "from ray.tune import Tuner\n",
    "\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    params={},\n",
    "    run_config=RunConfig(verbose=2),\n",
    "    preprocessor=None,\n",
    "    scaling_config=None,\n",
    "    label_column=\"Y\",\n",
    "    datasets={\"train\": dataset}\n",
    ")\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
