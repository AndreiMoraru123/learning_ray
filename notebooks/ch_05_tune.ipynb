{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maze_gym_env import Environment\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca16fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"A Policy suggests actions based on the current state.\n",
    "        We do this by tracking the value of each state-action pair.\n",
    "        \"\"\"\n",
    "        self.state_action_table = [\n",
    "            [0 for _ in range(env.action_space.n)]\n",
    "            for _ in range(env.observation_space.n)\n",
    "        ]\n",
    "        self.action_space = env.action_space\n",
    "\n",
    "    def get_action(self, state, explore=True, epsilon=0.1):\n",
    "        \"\"\"Explore randomly or exploit the best value currently available.\"\"\"\n",
    "        if explore and random.uniform(0, 1) < epsilon:\n",
    "            return self.action_space.sample()\n",
    "        return np.argmax(self.state_action_table[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation(object):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Simulates rollouts of an environment, given a policy to follow.\"\"\"\n",
    "        self.env = env\n",
    "\n",
    "    def rollout(self, policy, render=False, explore=True, epsilon=0.1):\n",
    "        \"\"\"Returns experiences for a policy rollout.\"\"\"\n",
    "        experiences = []\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy.get_action(state, explore, epsilon)\n",
    "            next_state, reward, done, info = self.env.step(action)\n",
    "            experiences.append([state, action, reward, next_state])\n",
    "            state = next_state\n",
    "            if render:\n",
    "                time.sleep(0.05)\n",
    "                self.env.render()\n",
    "\n",
    "        return experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(policy, experiences, weight=0.1, discount_factor=0.9):\n",
    "    \"\"\"Updates a given policy with a list of (state, action, reward, state)\n",
    "    experiences.\"\"\"\n",
    "    for state, action, reward, next_state in experiences:\n",
    "        next_max = np.max(policy.state_action_table[next_state])\n",
    "        value = policy.state_action_table[state][action]\n",
    "        new_value = (1 - weight) * value + weight * \\\n",
    "                    (reward + discount_factor * next_max)\n",
    "        policy.state_action_table[state][action] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff216071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_policy(env, num_episodes=10000, weight=0.1, discount_factor=0.9):\n",
    "    \"\"\"Training a policy by updating it with rollout experiences.\"\"\"\n",
    "    policy = Policy(env)\n",
    "    sim = Simulation(env)\n",
    "    for _ in range(num_episodes):\n",
    "        experiences = sim.rollout(policy)\n",
    "        update_policy(policy, experiences, weight, discount_factor)\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae31c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_policy(env, policy, num_episodes=10):\n",
    "    \"\"\"Evaluate a trained policy through rollouts.\"\"\"\n",
    "    simulation = Simulation(env)\n",
    "    steps = 0\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        experiences = simulation.rollout(policy, render=True, explore=False)\n",
    "        steps += len(experiences)\n",
    "\n",
    "    print(f\"{steps / num_episodes} steps on average \"\n",
    "          f\"for a total of {num_episodes} episodes.\")\n",
    "\n",
    "    return steps / num_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebc4b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::search_space[]\n",
    "import random\n",
    "search_space = []\n",
    "for i in range(10):\n",
    "    random_choice = {\n",
    "        'weight': random.uniform(0, 1),\n",
    "        'discount_factor': random.uniform(0, 1)\n",
    "    }\n",
    "    search_space.append(random_choice)\n",
    "# end::search_space[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::objective[]\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7cf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def objective(config):  # <1>\n",
    "    environment = Environment()\n",
    "    policy = train_policy(  # <2>\n",
    "        environment,\n",
    "        weight=config[\"weight\"],\n",
    "        discount_factor=config[\"discount_factor\"]\n",
    "    )\n",
    "    score = evaluate_policy(environment, policy)  # <3>\n",
    "    return [score, config]  # <4>\n",
    "# end::objective[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::random_search[]\n",
    "result_objects = [objective.remote(choice) for choice in search_space]\n",
    "results = ray.get(result_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3cb86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "results.sort(key=lambda x: x[0])\n",
    "print(results[-1])\n",
    "# end::random_search[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19c64c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::tune_search_space[]\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92395904",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"weight\": tune.uniform(0, 1),\n",
    "    \"discount_factor\": tune.uniform(0, 1),\n",
    "}\n",
    "# end::tune_search_space[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea081a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_objective[]\n",
    "def tune_objective(config):\n",
    "    environment = Environment()\n",
    "    policy = train_policy(\n",
    "        environment,\n",
    "        weight=config[\"weight\"],\n",
    "        discount_factor=config[\"discount_factor\"]\n",
    "    )\n",
    "    score = evaluate_policy(environment, policy)\n",
    "\n",
    "    return {\"score\": score}\n",
    "# end::tune_objective[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e12f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_analysis[]\n",
    "analysis = tune.run(tune_objective, config=search_space)\n",
    "print(analysis.get_best_config(metric=\"score\", mode=\"min\"))\n",
    "# end::tune_analysis[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74760547",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::tune_bo[]\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68025522",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = BayesOptSearch(random_search_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    tune_objective,\n",
    "    config=search_space,\n",
    "    metric=\"score\",\n",
    "    mode=\"min\",\n",
    "    search_alg=algo,\n",
    "    stop={\"training_iteration\": 10},\n",
    ")\n",
    "# end::tune_bo[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4804e10",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "TODO docs say \"minimize\" but mode is \"max\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d980391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::scheduler_obj[]\n",
    "def objective(config):\n",
    "    for step in range(30):  # <1>\n",
    "        score = config[\"weight\"] * (step ** 0.5) + config[\"bias\"]\n",
    "        tune.report(score=score)  # <2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098acfaa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "search_space = {\"weight\": tune.uniform(0, 1), \"bias\": tune.uniform(0, 1)}\n",
    "# end::scheduler_obj[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5747259",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::tune_scheduler[]\n",
    "from ray.tune.schedulers import HyperBandScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609182e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scheduler = HyperBandScheduler(metric=\"score\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    scheduler=scheduler,\n",
    "    num_samples=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.get_best_config(metric=\"score\", mode=\"min\"))\n",
    "# end::tune_scheduler[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_metrics_1[]\n",
    "from ray import tune\n",
    "from ray.tune import Callback\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintResultCallback(Callback):\n",
    "    def on_trial_result(self, iteration, trials, trial, result, **info):\n",
    "        print(f\"Trial {trial} in iteration {iteration}, \"\n",
    "              f\"got result: {result['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "    for step in range(30):\n",
    "        score = config[\"weight\"] * (step ** 0.5) + config[\"bias\"]\n",
    "        tune.report(score=score, step=step, more_metrics={})\n",
    "# end::tune_metrics_1[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_metrics_2[]\n",
    "search_space = {\"weight\": tune.uniform(0, 1), \"bias\": tune.uniform(0, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16402a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    mode=\"min\",\n",
    "    metric=\"score\",\n",
    "    callbacks=[PrintResultCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = analysis.best_trial\n",
    "print(pretty_print(best.last_result))\n",
    "# end::tune_metrics_2[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: don't make this hardcoded?\n",
    "# tag::tune_resume[]\n",
    "analysis = tune.run(\n",
    "    objective,\n",
    "    name=\"/Users/maxpumperla/ray_results/objective_2022-05-23_15-52-01\",\n",
    "    resume=True,\n",
    "    config=search_space)\n",
    "# end::tune_resume[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc192314",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::tune_stop_dict[]\n",
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    stop={\"training_iteration\": 10})\n",
    "# end::tune_stop_dict[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_stop_function[]\n",
    "def stopper(trial_id, result):\n",
    "    return result[\"score\"] < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43156ca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    stop=stopper)\n",
    "# end::tune_stop_function[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b889ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_custom_space[]\n",
    "from ray import tune\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bfb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"weight\": tune.sample_from(\n",
    "        lambda context: np.random.uniform(low=0.0, high=1.0)\n",
    "    ),\n",
    "    \"bias\": tune.sample_from(\n",
    "        lambda context: context.config.weight * np.random.normal()\n",
    "    )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387de179",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tune.run(objective, config=search_space)\n",
    "# end::tune_custom_space[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab4693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_rllib[]\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ff5fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    \"DQN\",\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    "    config={\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"lr\": tune.uniform(1e-5, 1e-4),\n",
    "        \"train_batch_size\": tune.choice([10000, 20000, 40000]),\n",
    "    },\n",
    ")\n",
    "# end::tune_rllib[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0801ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_keras_1[]\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc76d8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    num_classes = 10\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "# end::tune_keras_1[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tune_keras_2[]\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from ray.tune.integration.keras import TuneReportCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40861ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    model.add(Dense(config[\"hidden\"], activation=config[\"activation\"]))\n",
    "    model.add(Dropout(config[\"rate\"]))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[TuneReportCallback({\"mean_accuracy\": \"accuracy\"})])\n",
    "# end::tune_keras_2[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fa463",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::tune_keras_3[]\n",
    "from ray import tune\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = [{\"rate\": 0.2, \"hidden\": 128, \"activation\": \"relu\"}]\n",
    "algo = HyperOptSearch(points_to_evaluate=initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a28bc5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"rate\": tune.uniform(0.1, 0.5),\n",
    "    \"hidden\": tune.randint(32, 512),\n",
    "    \"activation\": tune.choice([\"relu\", \"tanh\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    objective,\n",
    "    name=\"keras_hyperopt_exp\",\n",
    "    search_alg=algo,\n",
    "    metric=\"mean_accuracy\",\n",
    "    mode=\"max\",\n",
    "    stop={\"mean_accuracy\": 0.99},\n",
    "    num_samples=10,\n",
    "    config=search_space,\n",
    ")\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "# end::tune_keras_3[]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
