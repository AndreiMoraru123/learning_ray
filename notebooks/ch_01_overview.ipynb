{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a88bf0d1",
      "metadata": {
        "id": "a88bf0d1"
      },
      "source": [
        "# An Overview of Ray\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5755b31b",
      "metadata": {
        "id": "5755b31b"
      },
      "source": [
        "One of the reasons we need efficient distributed computing is that we’re collecting\n",
        "ever more data with a large variety at increasing speeds. The storage systems, data\n",
        "processing and analytics engines that have emerged in the last decade are crucially\n",
        "important to the success of many companies. Interestingly, most “big data” technologies\n",
        "are built for and operated by (data) engineers, that are in charge of data\n",
        "collection and processing tasks. The rationale is to free up data scientists to do\n",
        "what they’re best at. As a data science practitioner you might want to focus on training\n",
        "complex machine learning models, running efficient hyperparameter selection,\n",
        "building entirely new and custom models or simulations, or serving your models to\n",
        "showcase them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6cebcd0",
      "metadata": {
        "id": "f6cebcd0"
      },
      "source": [
        "At the same time, it might be inevitable to scale these workloads to a compute\n",
        "cluster. To do that, the distributed system of your choice needs to support all of these\n",
        "fine-grained “big compute” tasks, potentially on specialized hardware. Ideally, it also\n",
        "fits into the big data tool chain you’re using and is fast enough to meet your latency\n",
        "requirements. In other words, distributed computing has to be powerful and flexible\n",
        "enough for complex data science workloads — and Ray can help you with that.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00480805",
      "metadata": {
        "id": "00480805"
      },
      "source": [
        "Python is likely the most popular language for data science today, and it’s certainly\n",
        "the one we find the most useful for our daily work. By now it’s over 30 years old,\n",
        "but has a still growing and active community. The rich [PyData ecosystem](https://\n",
        "pydata.org/) is an essential part of a data scientist’s toolbox. How can you make sure\n",
        "to scale out your workloads while still leveraging the tools you need? That’s a difficult\n",
        "problem, especially since communities can’t be forced to just toss their toolbox, or\n",
        "programming language. That means distributed computing tools for data science\n",
        "have to be built for their existing community\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b2dc7e",
      "metadata": {
        "id": "88b2dc7e"
      },
      "source": [
        "Every chapter of this book has an executable notebook that you can run. If you want run the code while following this chapter, you can run this notebook locally or directly in [Colab](https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_01_overview.ipynb):\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_01_overview.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d7dd72",
      "metadata": {
        "id": "a2d7dd72"
      },
      "source": [
        "For this chapter you need to install the following dependencies. We guide you through each dependency and when you need it later on, but if you're impatient you can install them all right now:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d03d5b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d03d5b1",
        "outputId": "5195fe1b-2f55-4f8e-b80e-06706f6f8989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray[rllib,serve,tune]\n",
            "  Downloading ray-2.49.2-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (8.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (3.19.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (2.32.4)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[rllib,serve,tune])\n",
            "  Downloading virtualenv-20.34.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (1.75.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (0.116.2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (1.37.0)\n",
            "Collecting aiohttp_cors (from ray[rllib,serve,tune])\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (0.48.0)\n",
            "Collecting py-spy>=0.4.0 (from ray[rllib,serve,tune])\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Collecting colorful (from ray[rllib,serve,tune])\n",
            "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting opentelemetry-proto (from ray[rllib,serve,tune])\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (3.12.15)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (0.35.0)\n",
            "Collecting watchfiles (from ray[rllib,serve,tune])\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (2.11.9)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (7.3.1)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (0.22.1)\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[rllib,serve,tune])\n",
            "  Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opencensus (from ray[rllib,serve,tune])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (2.2.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[rllib,serve,tune])\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (18.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (2025.3.0)\n",
            "Requirement already satisfied: dm_tree in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (0.1.9)\n",
            "Collecting gymnasium==1.1.1 (from ray[rllib,serve,tune])\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting lz4 (from ray[rllib,serve,tune])\n",
            "  Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting ormsgpack==1.7.0 (from ray[rllib,serve,tune])\n",
            "  Downloading ormsgpack-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from ray[rllib,serve,tune]) (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.1.1->ray[rllib,serve,tune]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.1.1->ray[rllib,serve,tune]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.1.1->ray[rllib,serve,tune]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.1.1->ray[rllib,serve,tune]) (0.0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[rllib,serve,tune]) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->ray[rllib,serve,tune]) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->ray[rllib,serve,tune]) (0.58b0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api==1.37.0->opentelemetry-sdk>=1.30.0->ray[rllib,serve,tune]) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[rllib,serve,tune]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[rllib,serve,tune]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[rllib,serve,tune]) (0.4.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[rllib,serve,tune])\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[rllib,serve,tune]) (4.4.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from dm_tree->ray[rllib,serve,tune]) (1.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from dm_tree->ray[rllib,serve,tune]) (1.17.3)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette->ray[rllib,serve,tune]) (4.10.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[rllib,serve,tune]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[rllib,serve,tune]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[rllib,serve,tune]) (0.27.1)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[rllib,serve,tune])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[rllib,serve,tune]) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[rllib,serve,tune]) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ray[rllib,serve,tune]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ray[rllib,serve,tune]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ray[rllib,serve,tune]) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray[rllib,serve,tune]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ray[rllib,serve,tune]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->ray[rllib,serve,tune]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ray[rllib,serve,tune]) (2025.8.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]; extra == \"serve\"->ray[rllib,serve,tune]) (0.16.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]; extra == \"serve\"->ray[rllib,serve,tune])\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]; extra == \"serve\"->ray[rllib,serve,tune]) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]; extra == \"serve\"->ray[rllib,serve,tune])\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]; extra == \"serve\"->ray[rllib,serve,tune]) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette->ray[rllib,serve,tune]) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0->opentelemetry-sdk>=1.30.0->ray[rllib,serve,tune]) (3.23.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[rllib,serve,tune]) (0.6.1)\n",
            "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.34.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.7-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl (13 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.49.2-cp312-cp312-manylinux2014_x86_64.whl (70.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-spy, opencensus-context, distlib, colorful, virtualenv, uvloop, tensorboardX, ormsgpack, opentelemetry-proto, lz4, httptools, gymnasium, watchfiles, aiohttp_cors, ray, opencensus, opentelemetry-exporter-prometheus\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "Successfully installed aiohttp_cors-0.8.1 colorful-0.5.7 distlib-0.4.0 gymnasium-1.1.1 httptools-0.6.4 lz4-4.4.4 opencensus-0.11.4 opencensus-context-0.1.3 opentelemetry-exporter-prometheus-0.58b0 opentelemetry-proto-1.37.0 ormsgpack-1.7.0 py-spy-0.4.1 ray-2.49.2 tensorboardX-2.6.4 uvloop-0.21.0 virtualenv-20.34.0 watchfiles-1.1.0\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install \"ray[rllib, serve, tune]\"\n",
        "! pip install \"pyarrow\"\n",
        "! pip install \"tensorflow\"\n",
        "! pip install \"transformers\"\n",
        "! pip install \"pygame\" \"gym\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccf2050f",
      "metadata": {
        "id": "ccf2050f"
      },
      "source": [
        "To import utility files for this chapter on Colab you will also have to clone the repo and copy the code files to the base path of the runtime. You don't need to do this if you run the notebook locally, of course.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafdce2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafdce2c",
        "outputId": "23266e5c-efed-4081-8af8-59b267b66245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'learning_ray'...\n",
            "remote: Enumerating objects: 543, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/54)\u001b[K\rremote: Counting objects:   3% (2/54)\u001b[K\rremote: Counting objects:   5% (3/54)\u001b[K\rremote: Counting objects:   7% (4/54)\u001b[K\rremote: Counting objects:   9% (5/54)\u001b[K\rremote: Counting objects:  11% (6/54)\u001b[K\rremote: Counting objects:  12% (7/54)\u001b[K\rremote: Counting objects:  14% (8/54)\u001b[K\rremote: Counting objects:  16% (9/54)\u001b[K\rremote: Counting objects:  18% (10/54)\u001b[K\rremote: Counting objects:  20% (11/54)\u001b[K\rremote: Counting objects:  22% (12/54)\u001b[K\rremote: Counting objects:  24% (13/54)\u001b[K\rremote: Counting objects:  25% (14/54)\u001b[K\rremote: Counting objects:  27% (15/54)\u001b[K\rremote: Counting objects:  29% (16/54)\u001b[K\rremote: Counting objects:  31% (17/54)\u001b[K\rremote: Counting objects:  33% (18/54)\u001b[K\rremote: Counting objects:  35% (19/54)\u001b[K\rremote: Counting objects:  37% (20/54)\u001b[K\rremote: Counting objects:  38% (21/54)\u001b[K\rremote: Counting objects:  40% (22/54)\u001b[K\rremote: Counting objects:  42% (23/54)\u001b[K\rremote: Counting objects:  44% (24/54)\u001b[K\rremote: Counting objects:  46% (25/54)\u001b[K\rremote: Counting objects:  48% (26/54)\u001b[K\rremote: Counting objects:  50% (27/54)\u001b[K\rremote: Counting objects:  51% (28/54)\u001b[K\rremote: Counting objects:  53% (29/54)\u001b[K\rremote: Counting objects:  55% (30/54)\u001b[K\rremote: Counting objects:  57% (31/54)\u001b[K\rremote: Counting objects:  59% (32/54)\u001b[K\rremote: Counting objects:  61% (33/54)\u001b[K\rremote: Counting objects:  62% (34/54)\u001b[K\rremote: Counting objects:  64% (35/54)\u001b[K\rremote: Counting objects:  66% (36/54)\u001b[K\rremote: Counting objects:  68% (37/54)\u001b[K\rremote: Counting objects:  70% (38/54)\u001b[K\rremote: Counting objects:  72% (39/54)\u001b[K\rremote: Counting objects:  74% (40/54)\u001b[K\rremote: Counting objects:  75% (41/54)\u001b[K\rremote: Counting objects:  77% (42/54)\u001b[K\rremote: Counting objects:  79% (43/54)\u001b[K\rremote: Counting objects:  81% (44/54)\u001b[K\rremote: Counting objects:  83% (45/54)\u001b[K\rremote: Counting objects:  85% (46/54)\u001b[K\rremote: Counting objects:  87% (47/54)\u001b[K\rremote: Counting objects:  88% (48/54)\u001b[K\rremote: Counting objects:  90% (49/54)\u001b[K\rremote: Counting objects:  92% (50/54)\u001b[K\rremote: Counting objects:  94% (51/54)\u001b[K\rremote: Counting objects:  96% (52/54)\u001b[K\rremote: Counting objects:  98% (53/54)\u001b[K\rremote: Counting objects: 100% (54/54)\u001b[K\rremote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 543 (delta 40), reused 36 (delta 28), pack-reused 489 (from 1)\u001b[K\n",
            "Receiving objects: 100% (543/543), 113.91 MiB | 40.11 MiB/s, done.\n",
            "Resolving deltas: 100% (352/352), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AndreiMoraru123/learning_ray.git\n",
        "%cp -r learning_ray/notebooks/* ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13c5a63e",
      "metadata": {
        "id": "13c5a63e"
      },
      "source": [
        "## What is Ray?\n",
        "\n",
        "Ray is a great computing framework for the Python data science community because it is flexible and distributed, making it easy to use and understand. It allows you to efficiently parallelize Python programs on your own computer and run them on a cluster without much modification. Additionally, its high-level libraries are easy to set up and can be used together smoothly, and some of them, such as the reinforcement learning library, have a promising future as standalone projects. Even though its core is written in C++, Ray has always been focused on Python and integrates well with many important data science tools. It also has a expanding ecosystem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2795bed4",
      "metadata": {
        "id": "2795bed4"
      },
      "source": [
        "Ray is not the first framework for distributed Python, nor will it be the last, but it stands out for its ability to handle custom machine learning tasks with ease. Its various modules work well together, allowing for the flexible execution of complex workloads using familiar Python tools. This book aims to teach how to use Ray to effectively utilize distributed Python for machine learning purposes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ba089d",
      "metadata": {
        "id": "e8ba089d"
      },
      "source": [
        "Programming distributed systems can be challenging because it requires specific skills and experience. While these systems are designed to be efficient and allow users to focus on their tasks, they often have [\"leaky abstractions\"](https://www.joelonsoftware.com/2002/11/11/thelaw-of-leaky-abstractions) that can make it difficult to get clusters of computers to work as desired. In addition, many software systems require more resources than a single server can provide, and modern systems need to be able to handle failures and offer high availability. This means that applications may need to run on multiple machines or even in different data centers in order to function reliably.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08256e35",
      "metadata": {
        "id": "08256e35"
      },
      "source": [
        "Even if you are not very familiar with machine learning (ML) or artificial intelligence (AI), you have probably heard about recent advances in these fields. Some examples of these advances include Deepmind's Alpha-Fold, which is a system for solving the protein folding problem, and OpenAI's Codex, which helps software developers with the tedious parts of their job. It is commonly known that ML systems require a lot of data to be trained and that ML models tend to become larger. OpenAI has demonstrated that the amount of computing power needed to train AI models has been increasing exponentially, as shown in their paper \"AI and Compute.\" In their study, the operations needed for AI systems were measured in petaflops (thousands of trillion operations per second) and have doubled every 3.4 months since 2012.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a010dd",
      "metadata": {
        "id": "68a010dd"
      },
      "source": [
        "While Moore's Law suggests that computer transistors will double every two years, the use of distributed computing in machine learning can significantly increase the speed at which tasks are completed. While distributed computing may be seen as challenging, it would be beneficial to develop abstractions that allow for code to run on clusters without constantly considering individual machines and their interactions. By focusing specifically on AI workloads, it may be possible to make distributed computing more accessible and efficient.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a1fcd87",
      "metadata": {
        "id": "3a1fcd87"
      },
      "source": [
        "Researchers at RISELab at UC Berkeley developed Ray to improve the efficiency of their workloads by distributing them. These workloads were flexible in nature and did not fit into existing frameworks. Ray was also designed to handle the distribution of the work and allow researchers to focus on their work without worrying about the specifics of their compute cluster. It was created with a focus on high-performance and diverse workloads, and allows researchers to use their preferred Python tools.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28aaa68",
      "metadata": {
        "id": "b28aaa68"
      },
      "source": [
        "### Design Philosophy\n",
        "\n",
        "Ray was created with a focus on certain design principles. Its API aims to be straightforward and applicable to a wide range of situations, while the compute model is designed to be adaptable. Additionally, the system architecture is optimized for speed and the ability to handle increasing workloads. Let's delve into these points further.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02dea857",
      "metadata": {
        "id": "02dea857"
      },
      "source": [
        "#### Simplicity and abstraction\n",
        "\n",
        "Ray's API is not only simple to use, but it is also intuitive and easy to learn, as you will see in Chapter 2. Whether you want to use all the CPU cores on your laptop or leverage all the machines in your cluster, you can do so with minimal changes to your code. Ray handles task distribution and coordination behind the scenes, allowing you to focus on your work rather than worrying about the mechanics of distributed computing. Additionally, the API is very flexible and can easily be integrated with other tools. For example, Ray actors can interact with other distributed Python workloads, making it a useful \"glue code\" for connecting different systems and frameworks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119f1f1a",
      "metadata": {
        "id": "119f1f1a"
      },
      "source": [
        "#### Flexibility and heterogeneity\n",
        "\n",
        "Ray's API is created to allow users to easily write flexible and modular code for artificial intelligence tasks, especially those involving reinforcement learning. As long as the workload can be expressed in Python, it can be distributed using Ray. However, it is important to ensure that sufficient resources are available and to consider what should be distributed. Ray does not impose any limitations on what can be done with it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83621e6c",
      "metadata": {
        "id": "83621e6c"
      },
      "source": [
        "Ray is able to handle a variety of different computational tasks. For example, when working on a complex simulation, it is common for there to be different steps that take different amounts of time to complete. Some may take a long time while others only take a few milliseconds. Ray is able to efficiently schedule and execute these tasks, even if they need to be run in parallel. Additionally, Ray's framework allows for dynamic execution, which is helpful when subsequent tasks depend on the outcome of an earlier task. Overall, Ray provides flexibility in managing heterogeneous workflows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b637aa16",
      "metadata": {
        "id": "b637aa16"
      },
      "source": [
        "It is important to be able to adapt your resource usage and Ray allows for the use of different types of hardware. For example, certain tasks may require the use of a GPU while others may perform better on a CPU. Ray gives you the ability to choose the most appropriate hardware for each task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9752190b",
      "metadata": {
        "id": "9752190b"
      },
      "source": [
        "#### Speed and scalability\n",
        "\n",
        "One of the key features of Ray is its speed. It can handle millions of tasks per second with minimal latency, making it an efficient choice for distributed systems. Additionally, Ray is effective at distributing and scheduling tasks across a compute cluster, and it does so in a way that is fault-tolerant. Its auto-scaler can adjust the number of machines in the cluster to match current demand, which helps to minimize costs and ensure there are enough resources available to run workloads. In the event of failures, Ray is designed to recover quickly, further contributing to its overall speed. While we will delve into the specifics of Ray's architecture later on, for now, let's focus on how it can be used in practice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80cf37d6",
      "metadata": {
        "id": "80cf37d6"
      },
      "source": [
        "### Core, Libraries and Ecosystem\n",
        "\n",
        "Now that you are aware of the purpose and goals behind the creation of Ray, let's examine the three layers of the system. While there may be other ways to classify these layers, the approach used in this book is the most logical and understandable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "babe95e4",
      "metadata": {
        "id": "babe95e4"
      },
      "source": [
        "1. A low-level, distributed computing framework for Python with a concise core API and tooling for cluster deployment called Ray Core.\n",
        "2. A set of high-level libraries for built and maintained by the creators of Ray. This includes the so-called Ray AI Runtime (AIR) to use these libraries with a unified API in common machine learning workloads.\n",
        "3. A growing ecosystem of integrations and partnerships with other notable\n",
        "   projects, which span many aspects of the first two layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f45267d",
      "metadata": {
        "id": "4f45267d"
      },
      "source": [
        "There are several layers to explore in this chapter. The core of Ray's engine, with its API at the center, serves as the foundation for everything else. The data science libraries in Ray build on top of this core and offer a specialized interface. Many data scientists will use these libraries directly, while those working in ML or platform engineering may focus on creating tools that extend the Ray Core API. Ray AIR serves as a connector between the various Ray libraries and provides a consistent framework for handling common AI tasks. Additionally, there are a increasing number of third-party integrations available for Ray that can be utilized by experienced practitioners. We will examine each of these layers in more detail.\n",
        "\n",
        "Below is a quick preview of what libraries and integrations each layer consists of. Maybe you already spot a few of your favorite tools from the ecosystem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a551fa5c",
      "metadata": {
        "id": "a551fa5c"
      },
      "source": [
        "![Ray Layers](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ray_layers.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4462377",
      "metadata": {
        "id": "f4462377",
        "lines_to_next_cell": 2
      },
      "source": [
        "## A framework for distributed computing\n",
        "\n",
        "At its core, Ray is a distributed computing framework.\n",
        "We'll provide you with just the basic terminology here, and talk about Ray's\n",
        "architecture in depth in chapter 2.\n",
        "In short, Ray sets up and manages clusters of computers so that you can run\n",
        "distributed tasks on them.\n",
        "A ray cluster consists of nodes that are connected to each other via a network.\n",
        "You program against the so-called _driver_, the program root, which lives on\n",
        "the _head node_.\n",
        "The driver can run _jobs_, that is a collection of tasks, that are run on the nodes\n",
        "in the cluster.\n",
        "Specifically, the individual tasks of a job are run on _worker_ processes on\n",
        "worker nodes\\_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4c2640",
      "metadata": {
        "id": "0b4c2640"
      },
      "source": [
        "![Ray cluster](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/simple_cluster.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8668e1ae",
      "metadata": {
        "id": "8668e1ae",
        "lines_to_next_cell": 2
      },
      "source": [
        "What's interesting is that a Ray cluster can also be a _local cluster_, i.e. a cluster\n",
        "consisting just of your own computer.\n",
        "In this case, there's just one node, namely the head node, which has the driver\n",
        "process and some worker processes.\n",
        "\n",
        "With that knowledge at hand, it's time to get your hands dirty and run your first\n",
        "local Ray cluster.\n",
        "Installing Ray on any of the major operating systems should work seamlessly\n",
        "using `pip`:\n",
        "\n",
        "```\n",
        "pip install \"ray[rllib, tune, serve]==2.2.0\"\n",
        "```\n",
        "\n",
        "With a simple `pip install ray` you would have installed just the very basics of Ray.\n",
        "Since we want to explore some advanced features, we installed the \"extras\" `rllib`\n",
        "and `tune`, which we'll discuss in a bit.\n",
        "Depending on your system configuration you may not need the quotation marks in the\n",
        "above installation command.\n",
        "\n",
        "Next, go ahead and start a Python session.\n",
        "You could use the `ipython` interpreter, which I find to be the most suitable\n",
        "environment for following along simple examples.\n",
        "The choice is up to you, but in any case please remember to use Python version\n",
        "`3.7` or later.\n",
        "In your Python session you can now easily import and initialize Ray as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a29d6ee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "a29d6ee5",
        "outputId": "8c03dc1d-6a21-4ab2-d7e0-7a075ef0b8cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:08:00,957\tERROR services.py:1357 -- Failed to start the dashboard \n",
            "2025-09-30 17:08:00,969\tERROR services.py:1382 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
            "2025-09-30 17:08:00,977\tERROR services.py:1426 -- \n",
            "The last 20 lines of /tmp/ray/session_2025-09-30_17-07-39_354347_208/logs/dashboard.log (it contains the error message from the dashboard): \n",
            "2025-09-30 17:07:45,766\tINFO utils.py:338 -- Available modules: [<class 'ray.dashboard.modules.usage_stats.usage_stats_head.UsageStatsHead'>]\n",
            "2025-09-30 17:07:45,766\tINFO head.py:235 -- DashboardHeadModules to load: None.\n",
            "2025-09-30 17:07:45,766\tINFO head.py:238 -- Loading DashboardHeadModule: <class 'ray.dashboard.modules.usage_stats.usage_stats_head.UsageStatsHead'>.\n",
            "2025-09-30 17:07:45,766\tINFO head.py:242 -- Loaded 1 dashboard head modules: [<ray.dashboard.modules.usage_stats.usage_stats_head.UsageStatsHead object at 0x14d3fc73ac00>].\n",
            "2025-09-30 17:07:45,766\tINFO utils.py:305 -- Get all modules by type: SubprocessModule\n",
            "2025-09-30 17:07:45,768\tINFO utils.py:338 -- Available modules: [<class 'ray.dashboard.modules.metrics.metrics_head.MetricsHead'>, <class 'ray.dashboard.modules.data.data_head.DataHead'>, <class 'ray.dashboard.modules.event.event_head.EventHead'>, <class 'ray.dashboard.modules.job.job_head.JobHead'>, <class 'ray.dashboard.modules.node.node_head.NodeHead'>, <class 'ray.dashboard.modules.reporter.reporter_head.ReportHead'>, <class 'ray.dashboard.modules.serve.serve_head.ServeHead'>, <class 'ray.dashboard.modules.state.state_head.StateHead'>, <class 'ray.dashboard.modules.train.train_head.TrainHead'>]\n",
            "2025-09-30 17:07:45,768\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.metrics.metrics_head.MetricsHead'>.\n",
            "2025-09-30 17:07:45,768\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.data.data_head.DataHead'>.\n",
            "2025-09-30 17:07:45,768\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.event.event_head.EventHead'>.\n",
            "2025-09-30 17:07:45,768\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.job.job_head.JobHead'>.\n",
            "2025-09-30 17:07:45,769\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.node.node_head.NodeHead'>.\n",
            "2025-09-30 17:07:45,769\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.reporter.reporter_head.ReportHead'>.\n",
            "2025-09-30 17:07:45,769\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.serve.serve_head.ServeHead'>.\n",
            "2025-09-30 17:07:45,769\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.state.state_head.StateHead'>.\n",
            "2025-09-30 17:07:45,769\tINFO head.py:292 -- Loading SubprocessModule: <class 'ray.dashboard.modules.train.train_head.TrainHead'>.\n",
            "2025-09-30 17:07:45,769\tINFO head.py:296 -- Loaded 9 subprocess modules: [<ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fc958500>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d40381f530>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d403618e30>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fc84dc70>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fc717050>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fd61eea0>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fc8ae720>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fc8ad4f0>, <ray.dashboard.subprocesses.handle.SubprocessModuleHandle object at 0x14d3fc8aec30>].\n",
            "\n",
            "2025-09-30 17:08:01,575\tINFO worker.py:1951 -- Started a local Ray instance.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
              "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
              "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
              "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
              "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
              "    </g>\n",
              "    <defs>\n",
              "        <clipPath id=\"clip0_4338_178347\">\n",
              "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
              "        </clipPath>\n",
              "    </defs>\n",
              "  </svg>\n",
              "</div>\n",
              "\n",
              "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
              "    <tr>\n",
              "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "        <td style=\"text-align: left\"><b>3.12.11</b></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "        <td style=\"text-align: left\"><b>2.49.2</b></td>\n",
              "    </tr>\n",
              "    \n",
              "</table>\n",
              "\n",
              "    </div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "RayContext(dashboard_url=None, python_version='3.12.11', ray_version='2.49.2', ray_commit='479fa716904109d9df4b56b98ca3c3350e1ec13c')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ray\n",
        "ray.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89de3a35",
      "metadata": {
        "id": "89de3a35"
      },
      "source": [
        "By running those two lines of code, you have set up a Ray cluster on your local machine. This cluster can take advantage of all the cores on your computer as worker processes. Currently, your Ray cluster isn't doing much, but that will change in the following section. The init function used to initiate the cluster is one of just six fundamental API calls that you will delve into in Chapter 2. Overall, the Ray Core API is straightforward and easy to use, but since it is also a lower-level interface, it takes time to create more complex examples with it. Chapter 2 includes a detailed first example to introduce you to the Ray Core API, and in Chapter 3 you will see how to build a more advanced Ray application for reinforcement learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dfedfee",
      "metadata": {
        "id": "3dfedfee"
      },
      "source": [
        "In the above example, you did not provide any arguments when calling the `ray.init(...)` function. If you wanted to use Ray on a real cluster, you would need to include more arguments in this init call, which is known as the Ray Client. The Ray Client is used to connect to an existing Ray cluster and interact with it. If you are interested in learning more about using the Ray Client to connect to your production clusters, you can refer to the [Ray documentation](https://docs.ray.io/en/latest/cluster/ray-client.html). Keep in mind that working with compute clusters can be complex, and there are many options for deploying Ray applications on them. For example, you can use cloud providers like AWS, GCP, or Azure to host your Ray clusters, or you can set up your own hardware or use tools like Kubernetes. We will revisit the topic of scaling workloads with Ray Clusters in Chapter 9, after discussing some specific applications of Ray in earlier chapters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "616cab30",
      "metadata": {
        "id": "616cab30"
      },
      "source": [
        "Before moving on the Ray’s higher level libraries, let’s briefly summarize the two\n",
        "foundational components of Ray as a distributed computation framework:\n",
        "\n",
        "- _Ray Clusters_: This component is in charge of allocating resources, creating nodes,\n",
        "  and ensuring they are healthy. A good way to get started with Ray Clusters is its\n",
        "  dedicated quick start guide (https://docs.ray.io/en/latest/cluster/quickstart.html).\n",
        "- _Ray Core_: Once your cluster is up and running, you use the Ray Core API\n",
        "  that to program against it. You can get started with Ray Core by following the\n",
        "  official walk-through (https://docs.ray.io/en/latest/ray-core/walkthrough.html) for\n",
        "  this component.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c684724",
      "metadata": {
        "id": "4c684724"
      },
      "source": [
        "## Ray's Libraries\n",
        "\n",
        "In this section, we will introduce the data science libraries included with Ray. To understand how these libraries can be beneficial to you, it's important to first have a general understanding of what data science entails. With this context in mind, you'll be able to see how Ray's higher-level libraries fit into the larger picture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b5e6fb",
      "metadata": {
        "id": "25b5e6fb"
      },
      "source": [
        "### Ray AIR and the Data Science Workflow\n",
        "\n",
        "The concept of \"data science\" (DS) has undergone significant changes in recent years, and you can find various definitions of the term online, some more useful than others. However, we believe that data science is the practice of using data to gain insights and develop practical applications. It is a field that involves building and understanding things, and is therefore quite practical and applied. In this sense, calling practitioners of this field \"data scientists\" is similar to calling hackers \"computer scientists\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a6c96d8",
      "metadata": {
        "id": "9a6c96d8"
      },
      "source": [
        "Data science involves a series of steps that involve identifying and gathering the necessary data, processing it, creating models, and implementing solutions. While machine learning may be a part of this process, it is not always necessary. If machine learning is included, there may be additional steps involved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c925fab2",
      "metadata": {
        "id": "c925fab2"
      },
      "source": [
        "- _Data Processing_: To use machine learning effectively, you must prepare the data in a way that the ML model can understand. This process, called feature engineering, involves selecting and transforming the data that will be input into the model. It can be a challenging task, so it is helpful to have access to reliable tools to assist with it.\n",
        "- _Model Training_: For machine learning, it is necessary to train your algorithms on data that has been previously processed. This involves selecting the appropriate algorithm for the task at hand. Having a diverse range of algorithms to choose from can also be beneficial.\n",
        "- _Hyperparameter Tuning_: During the process of training a machine learning model, certain parameters can be fine-tuned in order to improve its performance. In addition to these model parameters, there are also hyperparameters that can be adjusted before training begins. The proper adjustment of these hyperparameters can significantly impact the effectiveness of the final machine learning model. Fortunately, there are tools available to assist with the process of optimizing these hyperparameters.\n",
        "- _Model Serving_: The deployment of trained models is necessary in order to provide access to them for those who need it. This process, known as serving a model, involves making it available through various means, such as using simple HTTP servers in prototypes or specialized software packages specifically designed for serving ML models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd3f2d2d",
      "metadata": {
        "id": "dd3f2d2d"
      },
      "source": [
        "It is important to note that this list is not exhaustive and there is more to consider when building machine learning applications. Nonetheless, it is undeniable that these four steps are critical for the success of a data science project that utilizes machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d9d3a9",
      "metadata": {
        "id": "49d9d3a9"
      },
      "source": [
        "![Data Science Workflow](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ds_workflow.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d395aa2",
      "metadata": {
        "id": "1d395aa2"
      },
      "source": [
        "Ray has created dedicated libraries for each of the four ML-specific steps mentioned earlier. These libraries include Ray Datasets for data processing, Ray Train for distributed model training, Ray RLlib for reinforcement learning workloads, Ray Tune for efficient hyperparameter tuning, and Ray Serve for serving models. It is important to note that all of these libraries are distributed by design, as that is how Ray is built.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7faef52c",
      "metadata": {
        "id": "7faef52c"
      },
      "source": [
        "Additionally, it is important to consider that these steps are usually not completed separately but rather as part of a larger process. It is beneficial to have all relevant libraries working smoothly together and to have a uniform API throughout the data science process. The Ray AI Runtime (AIR) was designed with this in mind, providing a common runtime and API for experiments and the capability to expand workloads as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b40b5e9",
      "metadata": {
        "id": "3b40b5e9"
      },
      "source": [
        "![Ray AIR](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/AIR.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9918c5a",
      "metadata": {
        "id": "f9918c5a"
      },
      "source": [
        "In this chapter, we will not be discussing the Ray AI Runtime API in depth (more on that can be found in Chapter 10). However, we can provide an overview of the components that contribute to it. Specifically, we will go through each of the DS libraries that make up Ray one by one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4312e12f",
      "metadata": {
        "id": "4312e12f"
      },
      "source": [
        "### Ray Data\n",
        "\n",
        "The first high-level library of Ray we talk about is called \"Ray Data\".\n",
        "This library contains a data structure aptly called `Dataset`, a multitude of\n",
        "connectors for loading data from various formats and systems,\n",
        "an API for transforming such datasets, a way to build data processing pipelines\n",
        "with them, and many integrations with other data processing frameworks.\n",
        "The `Dataset` abstraction builds on the powerful\n",
        "[Arrow framework](https://arrow.apache.org/).\n",
        "\n",
        "To use Ray Data, you need to install Arrow for Python, for instance by running\n",
        "`pip install pyarrow`.\n",
        "We'll now discuss a simple example that creates a distributed `Dataset` on your\n",
        "local Ray cluster from a Python data structure.\n",
        "Specifically, you'll create a dataset from a Python dictionary containing a\n",
        "string `name` and an integer-valued `data` for `10000` entries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "121d832a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "98696b753f6c43678fc15cf561ec2dca",
            "aa04d67da8da4125a23b209272748032",
            "85698680fc5e4903a4a43d9c07ffcc0d",
            "fdca4c62acbe42d4a01ea8dc8479bc41",
            "2b9dc688952c4ad498da02ad334deb78",
            "7ad5500aba6c4345bd00acc9b058ea5f",
            "7743a24f09df41eeb78260cf05d54de4",
            "06deb30d939d476d976a92157948c0cd",
            "72e6c3e2d4ad4b0eb961bae220c36d9d",
            "8e0b41347e334e10b212a8d7ca08485d",
            "f1bce0e275eb495fa057503506809385",
            "784d6cf3ecbd4df5a287ea636919c8d5",
            "90a6fc8a34ce427d9024517db0ca7bb0",
            "2739ad195d3f4da9ab907ac1b17b01bb",
            "611acd5f8bac470982e8567e91b59d6b",
            "597b26b228414cd9a9f643e96e9abf8d",
            "82df4c84f38f4e58afe6319c6042a6aa",
            "3737ac3ce297423faf846036900ac97a",
            "8571b5a99dab4712bd37a3dc14f6662b",
            "583de2664f814a80a3c708186bad9bdd",
            "459d56c6ef3d43c58714dc3fad4e8dd6",
            "fd616709c67e49c4a437c3b51f691436"
          ]
        },
        "id": "121d832a",
        "outputId": "97697b05-85a6-4f9b-e14a-ab52eb1450d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:08:47,825\tINFO dataset.py:3246 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
            "2025-09-30 17:08:47,836\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_1_0\n",
            "2025-09-30 17:08:47,856\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_1_0. Full logs are in /tmp/ray/session_2025-09-30_17-07-39_354347_208/logs/ray-data\n",
            "2025-09-30 17:08:47,857\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_1_0: InputDataBuffer[Input] -> LimitOperator[limit=5]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98696b753f6c43678fc15cf561ec2dca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running 0: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "784d6cf3ecbd4df5a287ea636919c8d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- limit=5 1: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:08:47,914\tWARNING resource_manager.py:134 -- ⚠️  Ray's object store is configured to use only 42.9% of available memory (3.7GiB out of 8.7GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
            "2025-09-30 17:08:48,820\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_1_0 execution finished in 0.96 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': '0', 'data': 0}\n",
            "{'name': '1', 'data': 1}\n",
            "{'name': '2', 'data': 2}\n",
            "{'name': '3', 'data': 3}\n",
            "{'name': '4', 'data': 4}\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "\n",
        "items = [{\"name\": str(i), \"data\": i} for i in range(10000)]\n",
        "ds = ray.data.from_items(items)\n",
        "ds.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c95752b",
      "metadata": {
        "id": "8c95752b"
      },
      "source": [
        "Great, now you have some rows, but what can you do with that data?\n",
        "The `Dataset` API bets heavily on functional programming, as it is very well suited\n",
        "for data transformations.\n",
        "Even though Python 3 made a point of hiding some of its functional programming\n",
        "capabilities, you're probably\n",
        "familiar with functionality such as `map`, `filter` and others.\n",
        "If not, it's easy enough to pick up.\n",
        "`map` takes each element of your dataset and transforms is into something\n",
        "else, in parallel.\n",
        "`filter` removes data points according to a boolean filter function.\n",
        "And the slightly more elaborate `flat_map` first maps values similarly to `map`,\n",
        "but then also \"flattens\" the result.\n",
        "For instance, if `map` would produce a list of lists, `flat_map` would flatten out\n",
        "the nested lists and give\n",
        "you just a list.\n",
        "Equipped with these three functional API calls, let's see how easily you can\n",
        "transform your dataset `ds`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e008dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "97c37de673ea40b4822863f440d0ce1d",
            "6a4eb136a46d4c68af85a3a337e5047f",
            "0569b9aa46e742289c5c381c46a5f159",
            "53875a8844b14fffbd5e5bae3e62f03a",
            "f3328ab57be541b88b8c3bdd307d9925",
            "b99c0ab043f04149889c5d92551327d0",
            "87c76671789c4dc98e879e724777a6cf",
            "b4391a3ed84f402e90b2f4ef200706f1",
            "9b334878791646f6a6ec040e08e9884f",
            "6dbe9b3080714011a6084730f270699d",
            "fc52ee5f63c641c189532ceef8a17490",
            "cfa2d2eba58e4dfeaba3b0cbe375e4fd",
            "738ef47f057f4db49757307d8ab27ed3",
            "7ce53f2c9dd14f7dbc6e23114e9866ca",
            "dc74e2c1234f456ea5575612536a5f1f",
            "764ae725bf354044b6eb01ba6738d839",
            "f8ded6304e8e48fa822001d44f0cd2d3",
            "51ad5a92c8e14e8eadc9ea11a8e583b2",
            "c6e51426c3b1422fa6010aab4bbad966",
            "b2ebbc4caa364718a3f5509503d1f778",
            "585646ebd1654b109e20cb613f4a720c",
            "576e044ada0c43a9a86a0c93f891eed5",
            "ad1b43d4bc6742a9970879ea0d09e382",
            "2b80759ac6ab46cca8c454382d569359",
            "15401a1297884c54a43156719814fa02",
            "f45e93ceddb04cd9a43bbd209f66af32",
            "b89ed2fc9fd14939af30a59809c669d7",
            "4001b5291023412187566ab2ef7eb770",
            "2eaf5373dbf5465898cba64101dfe353",
            "2707c587007b425aa98d38e49d1daaa5",
            "399eeeb53b67448da6897196d48f07f6",
            "f19b0393c1f4410bbb8b5e477381cb27",
            "5129b73eb9ef41b68e472367b08b4c57",
            "c17e1ba88d7042538384a267847daa35",
            "6df832db45d145738c85de2366354d68",
            "6fa422e448a64cc599538dd76b893b24",
            "fb82ed4fa9df424b9de56bb8f289589c",
            "fff80dbd9bc54c329f7a56fbf1bda767",
            "c8d9f1968c7641e686897449286c34ec",
            "e086470b69d2426182d05d45b1d8f484",
            "fc6491a00f214ef38f2fedca7e5a8233",
            "665a884a9f4243088ac008892f641c15",
            "ddc0ea57bdbb4f058d0205cac421c8d6",
            "33a094e2df7a41c9b5c442bd4187fc70",
            "b47e40a55a4b4d299e80153502d1f2a0",
            "c672d1446e3b4cbc90a7dc9989982461",
            "ae5713eae99d4d379a345df0484e7d7c",
            "ddf07bce57ee46d3bd8c0b0d2b862303",
            "7fd302a22c874be5b6d66925d166827c",
            "4de84316525e4ac7aa0157baca22a018",
            "76e16d646c984beca8cfdbcdd6facc88",
            "9ce94e91a9954000969a413afc93df20",
            "6b28ed7e2614438ba64e7e4fd658e609",
            "c7e133b5628e4d6ba64b8a371550edba",
            "22391d536547409d8b308148f4d494bb",
            "1a66fc158b804103828261a368d69ddc",
            "ff1fe7d1c8024437a2945fa4c43061db",
            "d9bfeeb055834becb8c10a749dcc28b4",
            "05dc622e32cd48349c4595903f40ae8c",
            "f115f380e4504231850850475682f408",
            "25b9147e74af47b9bc7ab8bfb9716293",
            "d61716afaefe4355bf84c2ad1abd29fd",
            "a7190dee89684cd9aa567b77b7790c5b",
            "ecf2d852b10448a3a1832fc9a503ae88",
            "b12360a84ebc41e7989743a8d843b892",
            "6383d3417e9441468dcd74e0a5acf686"
          ]
        },
        "id": "b8e008dc",
        "outputId": "bbbbee50-9092-42b1-c05f-6aeae310ac07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:16:50,309\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_27_0\n",
            "2025-09-30 17:16:50,314\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_27_0. Full logs are in /tmp/ray/session_2025-09-30_17-07-39_354347_208/logs/ray-data\n",
            "2025-09-30 17:16:50,315\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_27_0: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)->Filter(<lambda>)] -> AggregateNumRows[AggregateNumRows]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97c37de673ea40b4822863f440d0ce1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfa2d2eba58e4dfeaba3b0cbe375e4fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- Map(<lambda>)->Filter(<lambda>) 1: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad1b43d4bc6742a9970879ea0d09e382",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- AggregateNumRows 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:16:52,897\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_27_0 execution finished in 2.58 seconds\n",
            "2025-09-30 17:16:52,922\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_29_0\n",
            "2025-09-30 17:16:52,932\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_29_0. Full logs are in /tmp/ray/session_2025-09-30_17-07-39_354347_208/logs/ray-data\n",
            "2025-09-30 17:16:52,934\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_29_0: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)->Filter(<lambda>)->FlatMap(<lambda>)] -> LimitOperator[limit=10]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c17e1ba88d7042538384a267847daa35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running 0: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b47e40a55a4b4d299e80153502d1f2a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- Map(<lambda>)->Filter(<lambda>)->FlatMap(<lambda>) 1: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a66fc158b804103828261a368d69ddc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- limit=10 2: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:16:53,209\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_29_0 execution finished in 0.27 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'data': 0}, {'data': 0}, {'data': 4}, {'data': 64}, {'data': 16}, {'data': 4096}, {'data': 36}, {'data': 46656}, {'data': 64}, {'data': 262144}]\n"
          ]
        }
      ],
      "source": [
        "squares = ds.map(lambda x: {\"data\" : x[\"data\"] ** 2})\n",
        "\n",
        "evens = squares.filter(lambda x: x[\"data\"] % 2 == 0)\n",
        "evens.count()\n",
        "\n",
        "cubes = evens.flat_map(lambda x: [{\"data\" : x[\"data\"]}, {\"data\" : x[\"data\"]**3}])\n",
        "sample = cubes.take(10)\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e42ee9",
      "metadata": {
        "id": "a3e42ee9"
      },
      "source": [
        "The drawback of `Dataset` transformations is that each step gets executed\n",
        "synchronously.\n",
        "In the above example this is a non-issue, but for complex tasks that e.g. mix\n",
        "reading files and processing data,\n",
        "you want an execution that can overlap the individual tasks.\n",
        "`DatasetPipeline` does exactly that.\n",
        "Let's rewrite the last example into a pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc16601a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "bf41d1e214db43b6a683fe6b00870026",
            "b5a5db18cb654fb9a50023bde87689cc",
            "3d265cf5ff2242eba848881f47f4421a",
            "d0aaa4ec59d24c6bb5b189072ddf9934",
            "857cb4d4119b4d1895f05c316e3801b8",
            "7288c49deb2f4f9da3f06da9057fa8a9",
            "e46202708fd04444a96532b5d9e31d02",
            "dd6cf269906542be9d0195cdd331363d",
            "4ab5e00a7b1f49ec8c285775e74a617e",
            "8624246d4be349f3b77d51a4638a731d",
            "465287792ee6429c91793dd33e0ed927",
            "6517550566814c0cb9c1123d6615a96f",
            "3700867389e64e5aab43e51c825994e6",
            "eea0d08d0d7c4fb8a249076cfc254777",
            "5a5b84cdd6bc40819bf8d2f9b9184a4d",
            "bae08db94aff4d41a74d5bb71e9e46f0",
            "7171d64ac55740e4b94956b145c8b8bf",
            "9a161e3c5c224cf2970a5f6594297df4",
            "11cf52cea33e4198b680395285f81c98",
            "16820b41fd884a5f8efb2af5c006e676",
            "ec0fb444df5b4a62af6a1f1e0bcf739f",
            "ef59a7f4aac1437891174cead1c7e928",
            "63c4d00260fa42c692b7c96ecb23cae0",
            "6c3eab5ec1c8479d8ef8f4f07242b66f",
            "810e84b511554653bd7a6419ab4e7423",
            "7ec2f2444e00431480818aa40a2ad4a6",
            "667bfe54c9d14af3a09a1cba15671185",
            "388a8e55d59b46e984cfd8ea05ca8cba",
            "cbf6227773d941efb053966e26e2837e",
            "54d4f0d62a134d21bd874010e1bd5581",
            "762bfb18f2aa425fbd4b9fc78aacec8c",
            "85b7162710cc4cfcb5f3038067b59371",
            "c245ee7d70c7448eb4c7a8d7d06d5804"
          ]
        },
        "id": "dc16601a",
        "outputId": "3284fa6e-2c93-4d30-b965-c612b7e98df8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ray/data/dataset.py:1464: UserWarning: Use 'expr' instead of 'fn' when possible for performant filters.\n",
            "  warnings.warn(\n",
            "2025-09-30 17:19:37,061\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_37_0\n",
            "2025-09-30 17:19:37,073\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_37_0. Full logs are in /tmp/ray/session_2025-09-30_17-07-39_354347_208/logs/ray-data\n",
            "2025-09-30 17:19:37,074\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_37_0: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)->Filter(<lambda>)->FlatMap(<lambda>)] -> LimitOperator[limit=10]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf41d1e214db43b6a683fe6b00870026",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running 0: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6517550566814c0cb9c1123d6615a96f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- Map(<lambda>)->Filter(<lambda>)->FlatMap(<lambda>) 1: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c4d00260fa42c692b7c96ecb23cae0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- limit=10 2: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:19:37,474\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_37_0 execution finished in 0.39 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': 0}\n",
            "{'data': 0}\n",
            "{'data': 4}\n",
            "{'data': 64}\n",
            "{'data': 16}\n",
            "{'data': 4096}\n",
            "{'data': 36}\n",
            "{'data': 46656}\n",
            "{'data': 64}\n",
            "{'data': 262144}\n"
          ]
        }
      ],
      "source": [
        "result = ds\\\n",
        "    .map(lambda x: {\"data\" : x[\"data\"] ** 2})\\\n",
        "    .filter(lambda x: x[\"data\"] % 2 == 0)\\\n",
        "    .flat_map(lambda x: [{\"data\" : x[\"data\"]}, {\"data\" : x[\"data\"]**3}])\n",
        "result.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecdf7fd1",
      "metadata": {
        "id": "ecdf7fd1"
      },
      "source": [
        "While there is much more that can be explored regarding Ray Datasets and its integration with certain data processing systems, we will have to postpone a more thorough discussion until Chapter 6.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12db60f0",
      "metadata": {
        "id": "12db60f0"
      },
      "source": [
        "### Model Training\n",
        "\n",
        "Next, we will examine the distributed training abilities of Ray through two libraries. The first library is specifically for reinforcement learning, while the second library is primarily focused on supervised learning tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20a3296",
      "metadata": {
        "id": "f20a3296"
      },
      "source": [
        "### RL with Ray RLlib\n",
        "\n",
        "We will begin with discussing Ray RLlib for reinforcement learning, a library that utilizes either TensorFlow or PyTorch as its underlying machine learning framework. Both of these frameworks are highly compatible with each other, so you can use whichever one you prefer without sacrificing much in terms of functionality. In this book, we will provide examples using both TensorFlow and PyTorch to give you a comprehensive understanding of how to use Ray with either framework. In this chapter we'll work with TensorFlow, which you can install by simply running the command \"pip install tensorflow\" in your terminal. If you wanted to, you could equally well install PyTorch instead.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b88c28e",
      "metadata": {
        "id": "2b88c28e"
      },
      "source": [
        "RLlib provides a command line tool called `rllib` that can be easily used to run examples. It was already installed when you ran \"pip install 'ray[rllib]'\" earlier. While you will primarily use the Python API for more advanced examples in Chapter 4, this tool allows you to quickly try out RL experiments using RLlib.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966a7dbc",
      "metadata": {
        "id": "966a7dbc"
      },
      "source": [
        "We will consider a classic control problem in which we try to balance a pole on a cart. Imagine that the pole is attached to the cart at a joint and is subject to the force of gravity. The cart is able to move along a frictionless track and we can give it a push to the left or right with a fixed force. If we do this properly, the pole should remain upright. For each time step in which the pole does not fall, we receive a reward of 1. Our goal is to collect as many rewards as possible and we want to see if we can use a reinforcement learning algorithm to help us achieve this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5432ed",
      "metadata": {
        "id": "9c5432ed"
      },
      "source": [
        "![Cartpole Env](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/cartpole.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f7c019",
      "metadata": {
        "id": "02f7c019"
      },
      "source": [
        "Our goal is to train a reinforcement learning agent that can perform two actions: pushing to the left or to the right, observe the consequences of these actions, and learn from the experience to maximize the reward. To achieve this using Ray RLlib, we can utilize a \"tuned example,\" which is a pre-set algorithm that works effectively for a specific problem. These examples can be easily run with a single command and RLlib offers a variety of them, which can be viewed by using this command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83dc3c83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83dc3c83",
        "outputId": "26d59499-7048-4a67-8006-4812ddf53073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: rllib: command not found\n"
          ]
        }
      ],
      "source": [
        "! rllib example list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d1aae96",
      "metadata": {
        "id": "1d1aae96"
      },
      "source": [
        "An example that is available is called cartpole-ppo, which utilizes the PPO algorithm to solve the cartpole problem in the CartPole-v1 environment from OpenAI Gym (https://gymnasium.farama.org/environments/classic_control/cart_pole/). You can access the configuration of this example by entering `rllib example get cartpole-ppo` in the command line. This will first download the example file from GitHub and then display the configuration, which is written in YAML format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d5a3c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0d5a3c6",
        "outputId": "709ddaa0-6022-4fc7-8abd-52d8d25c6b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: rllib: command not found\n"
          ]
        }
      ],
      "source": [
        "! rllib example get cartpole-ppo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e923a2fe",
      "metadata": {
        "id": "e923a2fe"
      },
      "source": [
        "While the specific details of the configuration file are not relevant at this time, it is important to note that you must include the Cartpole-v1 environment and the necessary RL configuration for the training process to function properly. You do not need any special equipment to run this configuration, and it should only take a few minutes to complete. In order to train this example, you will need to install the PyGame dependency by using the command `pip install pygame`, and then simply run:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2520fb30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2520fb30",
        "outputId": "d00cd1cd-2f8c-4db8-a23a-1aac8253f427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: rllib: command not found\n"
          ]
        }
      ],
      "source": [
        "! rllib example run cartpole-ppo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968bbd12",
      "metadata": {
        "id": "968bbd12"
      },
      "source": [
        "If you run this, RLlib creates a named experiment and logs important metrics such as\n",
        "the reward, or the `episode_reward_mean` for you. In the output of the training run,\n",
        "you should also see information about the machine (`loc`, meaning host name and\n",
        "port), as well as the status of your training runs. If your run is `TERMINATED`, but you’ve\n",
        "never seen a successfully `RUNNING` experiment in the log, something must have gone\n",
        "wrong. Here’s a sample snippet of a training run:\n",
        "\n",
        "```{text}\n",
        "+-----------------------------+----------+----------------+\n",
        "| Trial name | status | loc |\n",
        "|-----------------------------+----------+----------------|\n",
        "| PPO_CartPole-v0_9931e_00000 | RUNNING | 127.0.0.1:8683 |\n",
        "+-----------------------------+----------+----------------+\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cbc646f",
      "metadata": {
        "id": "3cbc646f"
      },
      "source": [
        "When the training run finishes and things went well, you should see the following\n",
        "output:\n",
        "\n",
        "```{text}\n",
        "Your training finished.\n",
        "Best available checkpoint for each trial:\n",
        "<checkpoint-path>/checkpoint_<number>\n",
        "\n",
        "You can now evaluate your trained algorithm from any checkpoint,\n",
        "e.g. by running:\n",
        "\n",
        "╭─────────────────────────────────────────────────────────────────────────╮\n",
        "│ rllib evaluate <checkpoint-path>/checkpoint_<number> --algo PPO         │\n",
        "╰─────────────────────────────────────────────────────────────────────────╯\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca9d054d",
      "metadata": {
        "id": "ca9d054d"
      },
      "source": [
        "Your local Ray checkpoint folder is `~/ray-results` by default. For the training\n",
        "configuration we used, your `<checkpoint-path>` should be of the form\n",
        "`~/ray_results/cartpole-ppo/PPO_CartPole-v1_<experiment_id>`. During training\n",
        "procedure, your intermediate and final model checkpoints get generated into this\n",
        "folder.\n",
        "\n",
        "To evaluate the performance of your trained RL algorithm, you can now evaluate it\n",
        "from checkpoint by copying the command the previous example training run printed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a631a09",
      "metadata": {
        "id": "7a631a09"
      },
      "outputs": [],
      "source": [
        "! rllib evaluate <checkpoint-path>/checkpoint_<number> --algo PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e553bda",
      "metadata": {
        "id": "4e553bda"
      },
      "source": [
        "Executing this command will display the rewards obtained by the RL algorithm you trained in the `CartPole-v1` environment. There is a lot more that can be done with RLlib, which will be discussed further in Chapter 4. The purpose of this example was to demonstrate how easy it is to begin using RLlib and the `rllib` command line tool through the use of the example and evaluate commands.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeaa244c",
      "metadata": {
        "id": "aeaa244c"
      },
      "source": [
        "#### Ray Train\n",
        "\n",
        "If you are interested in using Ray for supervised learning, rather than just reinforcement learning, you can use the Ray Train library. However, we do not have enough expertise with frameworks like TensorFlow to provide a detailed example of how to use Ray Train at this time. If you want to learn more about distributed training, you can move on to Chapter 6.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac35125e",
      "metadata": {
        "id": "ac35125e"
      },
      "source": [
        "### Ray Tune\n",
        "\n",
        "Naming things is hard, but the Ray team hit the spot with _Ray Tune_, which you can\n",
        "use to tune all\n",
        "sorts of parameters.\n",
        "Specifically, it was built to find good hyperparameters for machine learning models.\n",
        "The typical setup is as follows:\n",
        "\n",
        "- You want to run an extremely computationally expensive training function. In ML it's not uncommon\n",
        "  to run training procedures that take days, if not weeks, but let's say you're dealing with just a couple of minutes.\n",
        "- As result of training, you compute a so-called objective function. Usually you either want to maximize\n",
        "  your gains or minimize your losses in terms of performance of your experiment.\n",
        "- The tricky bit is that your training function might depend on certain parameters,\n",
        "  hyperparameters, that influence the value of your objective function.\n",
        "- You may have a hunch what individual hyperparameters should be, but tuning them all can be difficult.\n",
        "  Even if you can restrict these parameters to a sensible range, it's usually prohibitive to test a wide\n",
        "  range of combinations. Your training function is simply too expensive.\n",
        "\n",
        "What can you do to efficiently sample hyperparameters and get \"good enough\" results on your objective?\n",
        "The field concerned with solving this problem is called _hyperparameter optimization_ (HPO), and Ray Tune has\n",
        "an enormous suite of algorithms for tackling it.\n",
        "Let's look at a first example of Ray Tune used for the situation we just explained.\n",
        "The focus is yet again on Ray and its API, and not on a specific ML task (which we simply simulate for now).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05c4f66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d05c4f66",
        "outputId": "ac9e3b0f-417c-4495-85ae-4c48978f72b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------+\n",
            "| Configuration for experiment     training_function_2025-09-30_17-23-16   |\n",
            "+--------------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                           |\n",
            "| Number of trials                 25                                      |\n",
            "+--------------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/training_function_2025-09-30_17-23-16\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-09-30_17-07-39_354347_208/artifacts/2025-09-30_17-23-16/training_function_2025-09-30_17-23-16/driver_artifacts`\n",
            "\n",
            "Trial status: 25 PENDING\n",
            "Current time: 2025-09-30 17:23:16. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------+\n",
            "| Trial name                      status        x     y |\n",
            "+-------------------------------------------------------+\n",
            "| training_function_26b39_00000   PENDING    -1      -1 |\n",
            "| training_function_26b39_00001   PENDING    -0.5    -1 |\n",
            "| training_function_26b39_00002   PENDING     0      -1 |\n",
            "| training_function_26b39_00003   PENDING     0.5    -1 |\n",
            "| training_function_26b39_00004   PENDING     1      -1 |\n",
            "+-------------------------------------------------------+\n",
            "20 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00000 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00000 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                              -1 |\n",
            "| y                                              -1 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00001 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00001 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                              -0.5 |\n",
            "| y                                                -1 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00000 finished iteration 1 at 2025-09-30 17:23:45. Total running time: 28s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00000 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0039 |\n",
            "| time_total_s                                   10.0039 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                                1 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00000 completed after 1 iterations at 2025-09-30 17:23:45. Total running time: 28s\n",
            "\n",
            "Trial training_function_26b39_00001 finished iteration 1 at 2025-09-30 17:23:45. Total running time: 29s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00001 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00001 completed after 1 iterations at 2025-09-30 17:23:45. Total running time: 29s\n",
            "\n",
            "Trial status: 2 TERMINATED | 23 PENDING\n",
            "Current time: 2025-09-30 17:23:46. Total running time: 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   PENDING       0     -1                                          |\n",
            "| training_function_26b39_00003   PENDING       0.5   -1                                          |\n",
            "| training_function_26b39_00004   PENDING       1     -1                                          |\n",
            "| training_function_26b39_00005   PENDING      -1     -0.5                                        |\n",
            "| training_function_26b39_00006   PENDING      -0.5   -0.5                                        |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "18 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00002 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00002 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                               0 |\n",
            "| y                                              -1 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00003 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00003 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                              0.5 |\n",
            "| y                                               -1 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00002 finished iteration 1 at 2025-09-30 17:24:12. Total running time: 56s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00002 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0008 |\n",
            "| time_total_s                                   10.0008 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.70711 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00002 completed after 1 iterations at 2025-09-30 17:24:12. Total running time: 56s\n",
            "\n",
            "Trial training_function_26b39_00003 finished iteration 1 at 2025-09-30 17:24:12. Total running time: 56s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00003 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00003 completed after 1 iterations at 2025-09-30 17:24:12. Total running time: 56s\n",
            "\n",
            "Trial status: 4 TERMINATED | 21 PENDING\n",
            "Current time: 2025-09-30 17:24:17. Total running time: 1min 0s\n",
            "Logical resource usage: 1.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   PENDING       1     -1                                          |\n",
            "| training_function_26b39_00005   PENDING      -1     -0.5                                        |\n",
            "| training_function_26b39_00006   PENDING      -0.5   -0.5                                        |\n",
            "| training_function_26b39_00007   PENDING       0     -0.5                                        |\n",
            "| training_function_26b39_00008   PENDING       0.5   -0.5                                        |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "16 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00004 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00004 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                               1 |\n",
            "| y                                              -1 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00005 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00005 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                                -1 |\n",
            "| y                                              -0.5 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00004 finished iteration 1 at 2025-09-30 17:24:38. Total running time: 1min 22s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00004 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                                1 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00004 completed after 1 iterations at 2025-09-30 17:24:38. Total running time: 1min 22s\n",
            "\n",
            "Trial training_function_26b39_00005 finished iteration 1 at 2025-09-30 17:24:39. Total running time: 1min 23s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00005 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00005 completed after 1 iterations at 2025-09-30 17:24:39. Total running time: 1min 23s\n",
            "\n",
            "Trial status: 6 TERMINATED | 19 PENDING\n",
            "Current time: 2025-09-30 17:24:47. Total running time: 1min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00006   PENDING      -0.5   -0.5                                        |\n",
            "| training_function_26b39_00007   PENDING       0     -0.5                                        |\n",
            "| training_function_26b39_00008   PENDING       0.5   -0.5                                        |\n",
            "| training_function_26b39_00009   PENDING       1     -0.5                                        |\n",
            "| training_function_26b39_00010   PENDING      -1      0                                          |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "1 more TERMINATED, 14 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00006 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00006 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                              -0.5 |\n",
            "| y                                              -0.5 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00007 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00007 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                                 0 |\n",
            "| y                                              -0.5 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00006 finished iteration 1 at 2025-09-30 17:25:06. Total running time: 1min 50s\n",
            "+-------------------------------------------------------+\n",
            "| Trial training_function_26b39_00006 result            |\n",
            "+-------------------------------------------------------+\n",
            "| checkpoint_dir_name                                   |\n",
            "| time_this_iter_s                               10.001 |\n",
            "| time_total_s                                   10.001 |\n",
            "| training_iteration                                  1 |\n",
            "| score                                             0.5 |\n",
            "+-------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00006 completed after 1 iterations at 2025-09-30 17:25:06. Total running time: 1min 50s\n",
            "\n",
            "Trial training_function_26b39_00007 finished iteration 1 at 2025-09-30 17:25:06. Total running time: 1min 50s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00007 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.35355 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00007 completed after 1 iterations at 2025-09-30 17:25:06. Total running time: 1min 50s\n",
            "\n",
            "Trial status: 8 TERMINATED | 17 PENDING\n",
            "Current time: 2025-09-30 17:25:17. Total running time: 2min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00008   PENDING       0.5   -0.5                                        |\n",
            "| training_function_26b39_00009   PENDING       1     -0.5                                        |\n",
            "| training_function_26b39_00010   PENDING      -1      0                                          |\n",
            "| training_function_26b39_00011   PENDING      -0.5    0                                          |\n",
            "| training_function_26b39_00012   PENDING       0      0                                          |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "3 more TERMINATED, 12 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00008 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00008 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                               0.5 |\n",
            "| y                                              -0.5 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00009 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00009 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                                 1 |\n",
            "| y                                              -0.5 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00008 finished iteration 1 at 2025-09-30 17:25:33. Total running time: 2min 17s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00008 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0013 |\n",
            "| time_total_s                                   10.0013 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                              0.5 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00009 finished iteration 1 at 2025-09-30 17:25:33. Total running time: 2min 17s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00009 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00008 completed after 1 iterations at 2025-09-30 17:25:33. Total running time: 2min 17s\n",
            "\n",
            "Trial training_function_26b39_00009 completed after 1 iterations at 2025-09-30 17:25:33. Total running time: 2min 17s\n",
            "\n",
            "Trial status: 10 TERMINATED | 15 PENDING\n",
            "Current time: 2025-09-30 17:25:47. Total running time: 2min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x     y     iter     total time (s)      score |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1      -1        1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5    -1        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0      -1        1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5    -1        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1      -1        1            10.0007   1        |\n",
            "| training_function_26b39_00010   PENDING      -1       0                                        |\n",
            "| training_function_26b39_00011   PENDING      -0.5     0                                        |\n",
            "| training_function_26b39_00012   PENDING       0       0                                        |\n",
            "| training_function_26b39_00013   PENDING       0.5     0                                        |\n",
            "| training_function_26b39_00014   PENDING       1       0                                        |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "5 more TERMINATED, 10 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00010 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00010 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                              -1 |\n",
            "| y                                               0 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00011 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00011 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                              -0.5 |\n",
            "| y                                                 0 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00010 finished iteration 1 at 2025-09-30 17:26:01. Total running time: 2min 44s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00010 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.70711 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00010 completed after 1 iterations at 2025-09-30 17:26:01. Total running time: 2min 44s\n",
            "\n",
            "Trial training_function_26b39_00011 finished iteration 1 at 2025-09-30 17:26:01. Total running time: 2min 45s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00011 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.35355 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00011 completed after 1 iterations at 2025-09-30 17:26:01. Total running time: 2min 45s\n",
            "\n",
            "Trial status: 12 TERMINATED | 13 PENDING\n",
            "Current time: 2025-09-30 17:26:17. Total running time: 3min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00012   PENDING       0      0                                          |\n",
            "| training_function_26b39_00013   PENDING       0.5    0                                          |\n",
            "| training_function_26b39_00014   PENDING       1      0                                          |\n",
            "| training_function_26b39_00015   PENDING      -1      0.5                                        |\n",
            "| training_function_26b39_00016   PENDING      -0.5    0.5                                        |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "7 more TERMINATED, 8 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00012 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00012 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                               0 |\n",
            "| y                                               0 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00013 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00013 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                              0.5 |\n",
            "| y                                                0 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00012 finished iteration 1 at 2025-09-30 17:26:28. Total running time: 3min 11s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00012 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                                0 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00012 completed after 1 iterations at 2025-09-30 17:26:28. Total running time: 3min 11s\n",
            "\n",
            "Trial training_function_26b39_00013 finished iteration 1 at 2025-09-30 17:26:28. Total running time: 3min 11s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00013 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.35355 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00013 completed after 1 iterations at 2025-09-30 17:26:28. Total running time: 3min 11s\n",
            "\n",
            "Trial training_function_26b39_00015 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00015 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                               -1 |\n",
            "| y                                              0.5 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00014 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00014 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                               1 |\n",
            "| y                                               0 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial status: 14 TERMINATED | 2 RUNNING | 9 PENDING\n",
            "Current time: 2025-09-30 17:26:47. Total running time: 3min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00014   RUNNING       1      0                                          |\n",
            "| training_function_26b39_00015   RUNNING      -1      0.5                                        |\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00016   PENDING      -0.5    0.5                                        |\n",
            "| training_function_26b39_00017   PENDING       0      0.5                                        |\n",
            "| training_function_26b39_00018   PENDING       0.5    0.5                                        |\n",
            "| training_function_26b39_00019   PENDING       1      0.5                                        |\n",
            "| training_function_26b39_00020   PENDING      -1      1                                          |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "9 more TERMINATED, 4 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00015 finished iteration 1 at 2025-09-30 17:26:55. Total running time: 3min 38s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00015 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00015 completed after 1 iterations at 2025-09-30 17:26:55. Total running time: 3min 38s\n",
            "\n",
            "Trial training_function_26b39_00014 finished iteration 1 at 2025-09-30 17:26:55. Total running time: 3min 39s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00014 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.70711 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00014 completed after 1 iterations at 2025-09-30 17:26:55. Total running time: 3min 39s\n",
            "\n",
            "Trial training_function_26b39_00016 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00016 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                              -0.5 |\n",
            "| y                                               0.5 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00017 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00017 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                                0 |\n",
            "| y                                              0.5 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial status: 16 TERMINATED | 2 RUNNING | 7 PENDING\n",
            "Current time: 2025-09-30 17:27:17. Total running time: 4min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00016   RUNNING      -0.5    0.5                                        |\n",
            "| training_function_26b39_00017   RUNNING       0      0.5                                        |\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00018   PENDING       0.5    0.5                                        |\n",
            "| training_function_26b39_00019   PENDING       1      0.5                                        |\n",
            "| training_function_26b39_00020   PENDING      -1      1                                          |\n",
            "| training_function_26b39_00021   PENDING      -0.5    1                                          |\n",
            "| training_function_26b39_00022   PENDING       0      1                                          |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "11 more TERMINATED, 2 more PENDING\n",
            "\n",
            "Trial training_function_26b39_00016 finished iteration 1 at 2025-09-30 17:27:22. Total running time: 4min 6s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00016 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0008 |\n",
            "| time_total_s                                   10.0008 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                              0.5 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00016 completed after 1 iterations at 2025-09-30 17:27:22. Total running time: 4min 6s\n",
            "\n",
            "Trial training_function_26b39_00017 finished iteration 1 at 2025-09-30 17:27:22. Total running time: 4min 6s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00017 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.35355 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00017 completed after 1 iterations at 2025-09-30 17:27:22. Total running time: 4min 6s\n",
            "\n",
            "Trial training_function_26b39_00018 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00018 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                              0.5 |\n",
            "| y                                              0.5 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00019 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00019 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                                1 |\n",
            "| y                                              0.5 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial status: 18 TERMINATED | 2 RUNNING | 5 PENDING\n",
            "Current time: 2025-09-30 17:27:47. Total running time: 4min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00018   RUNNING       0.5    0.5                                        |\n",
            "| training_function_26b39_00019   RUNNING       1      0.5                                        |\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00020   PENDING      -1      1                                          |\n",
            "| training_function_26b39_00021   PENDING      -0.5    1                                          |\n",
            "| training_function_26b39_00022   PENDING       0      1                                          |\n",
            "| training_function_26b39_00023   PENDING       0.5    1                                          |\n",
            "| training_function_26b39_00024   PENDING       1      1                                          |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "13 more TERMINATED\n",
            "\n",
            "Trial training_function_26b39_00018 finished iteration 1 at 2025-09-30 17:27:48. Total running time: 4min 31s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00018 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                              0.5 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00018 completed after 1 iterations at 2025-09-30 17:27:48. Total running time: 4min 31s\n",
            "\n",
            "Trial training_function_26b39_00019 finished iteration 1 at 2025-09-30 17:27:49. Total running time: 4min 33s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00019 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0045 |\n",
            "| time_total_s                                   10.0045 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00019 completed after 1 iterations at 2025-09-30 17:27:49. Total running time: 4min 33s\n",
            "\n",
            "Trial training_function_26b39_00021 started with configuration:\n",
            "+-----------------------------------------------------+\n",
            "| Trial training_function_26b39_00021 config          |\n",
            "+-----------------------------------------------------+\n",
            "| x                                              -0.5 |\n",
            "| y                                                 1 |\n",
            "+-----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00020 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00020 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                              -1 |\n",
            "| y                                               1 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00021 finished iteration 1 at 2025-09-30 17:28:16. Total running time: 5min 0s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00021 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00020 finished iteration 1 at 2025-09-30 17:28:16. Total running time: 5min 0s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00020 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0019 |\n",
            "| time_total_s                                   10.0019 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                                1 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00021 completed after 1 iterations at 2025-09-30 17:28:16. Total running time: 5min 0s\n",
            "\n",
            "Trial training_function_26b39_00020 completed after 1 iterations at 2025-09-30 17:28:16. Total running time: 5min 0s\n",
            "\n",
            "Trial status: 22 TERMINATED | 3 PENDING\n",
            "Current time: 2025-09-30 17:28:17. Total running time: 5min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x     y     iter     total time (s)      score |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1      -1        1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5    -1        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0      -1        1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5    -1        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1      -1        1            10.0007   1        |\n",
            "| training_function_26b39_00022   PENDING       0       1                                        |\n",
            "| training_function_26b39_00023   PENDING       0.5     1                                        |\n",
            "| training_function_26b39_00024   PENDING       1       1                                        |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "17 more TERMINATED\n",
            "\n",
            "Trial training_function_26b39_00022 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00022 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                               0 |\n",
            "| y                                               1 |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00023 started with configuration:\n",
            "+----------------------------------------------------+\n",
            "| Trial training_function_26b39_00023 config         |\n",
            "+----------------------------------------------------+\n",
            "| x                                              0.5 |\n",
            "| y                                                1 |\n",
            "+----------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00022 finished iteration 1 at 2025-09-30 17:28:45. Total running time: 5min 28s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00022 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0015 |\n",
            "| time_total_s                                   10.0015 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.70711 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00022 completed after 1 iterations at 2025-09-30 17:28:45. Total running time: 5min 28s\n",
            "\n",
            "Trial training_function_26b39_00023 finished iteration 1 at 2025-09-30 17:28:45. Total running time: 5min 29s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00023 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0007 |\n",
            "| time_total_s                                   10.0007 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                          0.79057 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00023 completed after 1 iterations at 2025-09-30 17:28:45. Total running time: 5min 29s\n",
            "\n",
            "Trial status: 24 TERMINATED | 1 PENDING\n",
            "Current time: 2025-09-30 17:28:47. Total running time: 5min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x     y     iter     total time (s)      score |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1      -1        1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5    -1        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0      -1        1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5    -1        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1      -1        1            10.0007   1        |\n",
            "| training_function_26b39_00024   PENDING       1       1                                        |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "19 more TERMINATED\n",
            "\n",
            "Trial training_function_26b39_00024 started with configuration:\n",
            "+---------------------------------------------------+\n",
            "| Trial training_function_26b39_00024 config        |\n",
            "+---------------------------------------------------+\n",
            "| x                                               1 |\n",
            "| y                                               1 |\n",
            "+---------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 17:29:05,640\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/training_function_2025-09-30_17-23-16' in 0.0147s.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial training_function_26b39_00024 finished iteration 1 at 2025-09-30 17:29:05. Total running time: 5min 49s\n",
            "+--------------------------------------------------------+\n",
            "| Trial training_function_26b39_00024 result             |\n",
            "+--------------------------------------------------------+\n",
            "| checkpoint_dir_name                                    |\n",
            "| time_this_iter_s                               10.0006 |\n",
            "| time_total_s                                   10.0006 |\n",
            "| training_iteration                                   1 |\n",
            "| score                                                1 |\n",
            "+--------------------------------------------------------+\n",
            "\n",
            "Trial training_function_26b39_00024 completed after 1 iterations at 2025-09-30 17:29:05. Total running time: 5min 49s\n",
            "\n",
            "Trial status: 25 TERMINATED\n",
            "Current time: 2025-09-30 17:29:05. Total running time: 5min 49s\n",
            "Logical resource usage: 1.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| Trial name                      status          x      y     iter     total time (s)      score |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "| training_function_26b39_00000   TERMINATED   -1     -1          1            10.0039   1        |\n",
            "| training_function_26b39_00001   TERMINATED   -0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00002   TERMINATED    0     -1          1            10.0008   0.707107 |\n",
            "| training_function_26b39_00003   TERMINATED    0.5   -1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00004   TERMINATED    1     -1          1            10.0007   1        |\n",
            "| training_function_26b39_00005   TERMINATED   -1     -0.5        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00006   TERMINATED   -0.5   -0.5        1            10.001    0.5      |\n",
            "| training_function_26b39_00007   TERMINATED    0     -0.5        1            10.0007   0.353553 |\n",
            "| training_function_26b39_00008   TERMINATED    0.5   -0.5        1            10.0013   0.5      |\n",
            "| training_function_26b39_00009   TERMINATED    1     -0.5        1            10.0007   0.790569 |\n",
            "| training_function_26b39_00010   TERMINATED   -1      0          1            10.0006   0.707107 |\n",
            "| training_function_26b39_00011   TERMINATED   -0.5    0          1            10.0006   0.353553 |\n",
            "| training_function_26b39_00012   TERMINATED    0      0          1            10.0007   0        |\n",
            "| training_function_26b39_00013   TERMINATED    0.5    0          1            10.0006   0.353553 |\n",
            "| training_function_26b39_00014   TERMINATED    1      0          1            10.0006   0.707107 |\n",
            "| training_function_26b39_00015   TERMINATED   -1      0.5        1            10.0006   0.790569 |\n",
            "| training_function_26b39_00016   TERMINATED   -0.5    0.5        1            10.0008   0.5      |\n",
            "| training_function_26b39_00017   TERMINATED    0      0.5        1            10.0006   0.353553 |\n",
            "| training_function_26b39_00018   TERMINATED    0.5    0.5        1            10.0006   0.5      |\n",
            "| training_function_26b39_00019   TERMINATED    1      0.5        1            10.0045   0.790569 |\n",
            "| training_function_26b39_00020   TERMINATED   -1      1          1            10.0019   1        |\n",
            "| training_function_26b39_00021   TERMINATED   -0.5    1          1            10.0006   0.790569 |\n",
            "| training_function_26b39_00022   TERMINATED    0      1          1            10.0015   0.707107 |\n",
            "| training_function_26b39_00023   TERMINATED    0.5    1          1            10.0007   0.790569 |\n",
            "| training_function_26b39_00024   TERMINATED    1      1          1            10.0006   1        |\n",
            "+-------------------------------------------------------------------------------------------------+\n",
            "\n",
            "{'x': 0, 'y': 0}\n"
          ]
        }
      ],
      "source": [
        "from ray import tune\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def training_function(config):\n",
        "    x, y = config[\"x\"], config[\"y\"]\n",
        "    time.sleep(10)\n",
        "    score = objective(x, y)\n",
        "    tune.report({\"score\": score})\n",
        "\n",
        "\n",
        "def objective(x, y):\n",
        "    return math.sqrt((x**2 + y**2)/2)\n",
        "\n",
        "\n",
        "result = tune.run(\n",
        "    training_function,\n",
        "    config={\n",
        "        \"x\": tune.grid_search([-1, -.5, 0, .5, 1]),\n",
        "        \"y\": tune.grid_search([-1, -.5, 0, .5, 1])\n",
        "    })\n",
        "\n",
        "print(result.get_best_config(metric=\"score\", mode=\"min\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e790e45",
      "metadata": {
        "id": "2e790e45"
      },
      "source": [
        "Note how the output of this run is structurally similar to what you’ve\n",
        "seen in the RLlib example. That’s no coincidence, as RLlib (like many other Ray\n",
        "libraries) uses Ray Tune under the hood. If you look closely, you will see `PENDING`\n",
        "runs that wait for execution, as well as `RUNNING` and `TERMINATED` runs. Tune takes care\n",
        "of selecting, scheduling, and executing your training runs for you automatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f30412",
      "metadata": {
        "id": "a4f30412"
      },
      "source": [
        "This Tune example aims to identify the optimal values for parameters x and y for a training_function with the goal of minimizing a particular objective. Although the objective function may seem complicated as it involves calculating the sum of the squares of x and y, all of the values will be non-negative. Therefore, the lowest value is achieved when x and y are both equal to 0, resulting in an evaluation of 0 for the objective function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3298b6",
      "metadata": {
        "id": "7e3298b6"
      },
      "source": [
        "We do a so-called grid search over all possible parameter combinations. As we explicitly\n",
        "pass in five possible values for both x and y that’s a total of 25 combinations\n",
        "that get fed into the training function. These combinations are evaluated through the training function, which includes a 10 second sleep time. Without Ray's ability to parallelize the process, testing all of these combinations would take more than four minutes. However, on my laptop, this experiment only takes around 35 seconds to complete. The duration may vary depending on the device used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cab1adf",
      "metadata": {
        "id": "9cab1adf"
      },
      "source": [
        "If each training run took several hours, and there were 20 hyperparameters to consider instead of just two, it would not be practical to use grid search. This is especially true if you do not have a good idea of what range the parameters should be in. In these cases, you will need to use more advanced HPO methods like those offered by Ray Tune, which we will discuss in Chapter 5.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a7b0c80",
      "metadata": {
        "id": "9a7b0c80"
      },
      "source": [
        "### Ray Serve\n",
        "\n",
        "The last of Ray's high-level libraries we'll discuss specializes on model serving and is simply called _Ray Serve_.\n",
        "To see an example of it in action, you need a trained ML model to serve.\n",
        "Luckily, nowadays you can find many interesting models on the internet that have already been trained for you.\n",
        "For instance, _Hugging Face_ has a variety of models available for you to download directly in Python.\n",
        "The model we'll use is a language model called _GPT-2_ that takes text as input and produces text to\n",
        "continue or complete the input.\n",
        "For example, you can prompt a question and GPT-2 will try to complete it.\n",
        "\n",
        "Serving such a model is a good way to make it accessible.\n",
        "You may not now how to load and run a TensorFlow model on your computer, but you do now how\n",
        "to ask a question in plain English.\n",
        "Model serving hides the implementation details of a solution and lets users focus on providing\n",
        "inputs and understanding outputs of a model.\n",
        "\n",
        "To proceed, make sure to run `pip install transformers` to install the Hugging Face library\n",
        "that has the model we want to use.\n",
        "With that we can now import and start an instance of Ray's `serve` library, load and deploy a GPT-2\n",
        "model and ask it for the meaning of life, like so:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bb8ee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37bb8ee5",
        "outputId": "1aff64fa-2b1c-482f-ce29-dcafbcff9662"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO 2025-09-30 17:33:58,596 serve 208 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
            "INFO 2025-09-30 17:33:58,605 serve 208 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m 2025-09-30 17:34:05.742350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m E0000 00:00:1759253645.837947   10937 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m E0000 00:00:1759253645.888935   10937 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m W0000 00:00:1759253645.962733   10937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m W0000 00:00:1759253645.962814   10937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m W0000 00:00:1759253645.962821   10937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m W0000 00:00:1759253645.962826   10937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m 2025-09-30 17:34:05.993148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m INFO 2025-09-30 17:34:22,215 controller 10885 -- Deploying new version of Deployment(name='model', app='default') (initial target replicas: 1).\n",
            "\u001b[36m(ServeController pid=10885)\u001b[0m INFO 2025-09-30 17:34:22,321 controller 10885 -- Adding 1 replica to Deployment(name='model', app='default').\n",
            "\u001b[36m(ProxyActor pid=10941)\u001b[0m INFO 2025-09-30 17:34:22,228 proxy 172.28.0.12 -- Got updated endpoints: {Deployment(name='model', app='default'): EndpointInfo(route='/', app_is_cross_language=False)}.\n",
            "\u001b[36m(ProxyActor pid=10941)\u001b[0m INFO 2025-09-30 17:34:22,240 proxy 172.28.0.12 -- Started <ray.serve._private.router.SharedRouterLongPollClient object at 0x146dee11cad0>.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m 2025-09-30 17:34:34.122043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m E0000 00:00:1759253674.168165   11655 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m E0000 00:00:1759253674.179790   11655 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m W0000 00:00:1759253674.208791   11655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m W0000 00:00:1759253674.208847   11655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m W0000 00:00:1759253674.208850   11655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m W0000 00:00:1759253674.208853   11655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m 2025-09-30 17:34:34.217112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 2025-09-30 17:34:43,505 serve 208 -- Application 'default' is ready at http://127.0.0.1:8000/.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/serve/_private/replica.py:1397: UserWarning: Calling sync method 'model' directly on the asyncio loop. In a future version, sync methods will be run in a threadpool by default. Ensure your sync methods are thread safe or keep the existing behavior by making them `async def`. Opt into the new behavior by setting RAY_SERVE_RUN_SYNC_IN_THREADPOOL=1.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m Device set to use cpu\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"generated_text\":\"What's the meaning of life?\\n\\nI think we're a little bit on the short side of it, because life is, is a little bit on the long side. It's not all about the things that happen when we're in a certain mode of life, but the things that happen when we're in a certain mode of life.\\n\\nDo you plan on making a sequel to the previous season?\\n\\nYeah, I think the fact that we're doing this as a comedy is great. We've always wanted to make a comedy that's as funny and as interesting as it gets. We're going to try to make a comedy that's as funny and as interesting as it gets, but we're actually going to try to make it funnier.\\n\\nDo you want to continue your work with the show going forward?\\n\\nYeah, I don't want to think about it. I think the end of the season is going to be our biggest one yet. I think the end of the season is going to be the biggest one yet. I think the only thing we're going to do is make it bigger. We're going to make it bigger in the future that I think we're going to get.\\n\\nWill you be doing additional episodes in the future?\\n\\n\"}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ServeReplica:default:model pid=11603)\u001b[0m INFO 2025-09-30 17:35:21,287 default_model fj4qfe8m f45d4f07-cf31-457d-9d94-75e2a322826e -- GET / 200 37768.1ms\n"
          ]
        }
      ],
      "source": [
        "from ray import serve\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "\n",
        "serve.start()\n",
        "\n",
        "\n",
        "@serve.deployment\n",
        "def model(request):\n",
        "    language_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "    query = request.query_params[\"query\"]\n",
        "    return language_model(query, max_length=100)\n",
        "\n",
        "\n",
        "serve.run(model.bind())\n",
        "\n",
        "query = \"What's the meaning of life?\"\n",
        "response = requests.get(f\"http://localhost:8000/model?query={query}\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65135823",
      "metadata": {
        "id": "65135823"
      },
      "source": [
        "In Chapter 9, you will be taught how to correctly implement models in various situations. However, for now, I recommend that you experiment with this example and try different queries. If you repeatedly run the last two lines of code, you will get practically different answers every time. Here is a poetic statement that I queried on my computer, which has been slightly edited for younger readers:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f071a0c9",
      "metadata": {
        "id": "f071a0c9"
      },
      "source": [
        "```{text}\n",
        "[{\n",
        "\"generated_text\": \"What's the meaning of life?\\n\\n\n",
        "Is there one way or another of living?\\n\\n\n",
        "How does it feel to be trapped in a relationship?\\n\\n\n",
        "How can it be changed before it's too late?\n",
        "What did we call it in our time?\\n\\n\n",
        "Where do we fit within this world and what are we going to live for?\\n\\n\n",
        "My life as a person has been shaped by the love I've received from others.\"\n",
        "}]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab453063",
      "metadata": {
        "id": "ab453063"
      },
      "source": [
        "This is the end of our overview of the data science libraries within the second layer of Ray. These libraries, which we have discussed in this chapter, are all based on the Ray Core API. It is fairly simple to create new extensions for Ray, and there are a few more that we are unable to cover in this book. For example, the Ray Workflows library (https://docs.ray.io/en/latest/workflows/index.html) allows users to define and run long-term applications using Ray. Before we conclude this chapter, let's briefly examine the third layer of Ray, which is the expanding ecosystem surrounding the platform.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0926a41a",
      "metadata": {
        "id": "0926a41a"
      },
      "source": [
        "## The Ray Ecosystem\n",
        "\n",
        "Ray's libraries are powerful and should be discussed in more detail in the book. Although they are very useful for data science work, we don't want to give the impression that they are the only thing you need from now on. The most successful frameworks are those that work well with other solutions and ideas. It is better to concentrate on your strengths and use other tools to fill any gaps in your solution, which Ray does well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b073dd4",
      "metadata": {
        "id": "3b073dd4"
      },
      "source": [
        "Throughout the book, we will be discussing various libraries that have been built on top of Ray. Additionally, Ray has integrations with existing tools like Spark, Dask, and Pandas. For instance, you can use Ray Datasets, a data loading and compute library, with your existing project that utilizes data processing engines like Spark or Dask. Additionally, you can run the entire Dask ecosystem on a Ray cluster with the Dask-on-Ray scheduler or use the Spark on Ray project to integrate your Spark workloads with Ray. The Modin project also offers a distributed replacement for Pandas dataframes that utilizes Ray or Dask as the distributed execution engine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ba65e3",
      "metadata": {
        "id": "41ba65e3"
      },
      "source": [
        "Ray's approach is to integrate with various tools rather than trying to replace them, while still providing access to its own native library called Ray Datasets. This will be explored in more detail later in Chapter 11. It's noteworthy that many of the Ray libraries have the ability to seamlessly integrate with other tools as backends, often by creating common interfaces rather than establishing new standards. These interfaces enable you to perform tasks in a distributed manner, something that many of the backends may not offer or may not offer to the same degree.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e88155",
      "metadata": {
        "id": "84e88155"
      },
      "source": [
        "For example, Ray RLlib and Train both utilize the capabilities of TensorFlow and PyTorch. Additionally, Ray Tune allows for the use of a variety of HPO tools, such as Hyperopt, Optuna, Nevergrad, Ax, and SigOpt, among others. These tools are not automatically distributed, but Tune brings them together in a unified interface for distributed tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7279b0",
      "metadata": {
        "id": "8c7279b0"
      },
      "source": [
        "![Ray Layers](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ray_layers.png)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
