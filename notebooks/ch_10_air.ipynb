{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba89df43",
   "metadata": {},
   "source": [
    "# Chapter 10: Getting Started with the Ray AI Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900de5b",
   "metadata": {},
   "source": [
    "\n",
    "You can run this notebook directly in\n",
    "[Colab](https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_10_air.ipynb).\n",
    "\n",
    "The book has been written for Ray 2.2.0,which at the time of writing has not\n",
    "officially been released yet. If you are reading this and this version is already\n",
    "available, you can install it using `pip install ray==2.2.0`. If not, you can\n",
    "use a nightly wheel (here for Python 3.7 on Linux):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cbf0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-3.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f0182",
   "metadata": {},
   "source": [
    "Should you not run this notebook in Colab and need another type of wheel, please\n",
    "refer to Ray's [installation instructions for nightlies](https://docs.ray.io/en/latest/ray-overview/installation.html#install-nightlies).\n",
    "\n",
    "For this chapter you will also need to install the following dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8477db",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "! pip install -U \"ray[air]==2.2.0\" \"xgboost-ray>=0.1.10\" \"xgboost>=1.6.2\"\n",
    "! pip install -U \"numpy>=1.19.5\" \"pandas>=1.3.5\" \"pyarrow>=6.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020752a3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::data_preprocessor[]\n",
    "import ray\n",
    "from ray.data.preprocessors import StandardScaler\n",
    "\n",
    "\n",
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")  # <1>\n",
    "\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.2)\n",
    "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])  # <2>\n",
    "\n",
    "preprocessor = StandardScaler(columns=[\"mean radius\", \"mean texture\"])  # <3>\n",
    "# end::data_preprocessor[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867208c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::trainer[]\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=ScalingConfig(  # <1>\n",
    "        num_workers=2,\n",
    "        use_gpu=False,\n",
    "    ),\n",
    "    label_column=\"target\",\n",
    "    num_boost_round=20,  # <2>\n",
    "    params={\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},  # <3>\n",
    "    preprocessor=preprocessor,  # <4>\n",
    ")\n",
    "result = trainer.fit()  # <5>\n",
    "print(result.metrics)\n",
    "# end::trainer[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::tuner[]\n",
    "from ray import tune\n",
    "\n",
    "param_space = {\"params\": {\"max_depth\": tune.randint(1, 9)}}\n",
    "metric = \"train-logloss\"\n",
    "\n",
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,  # <1>\n",
    "    param_space=param_space,  # <2>\n",
    "    run_config=RunConfig(verbose=1),\n",
    "    tune_config=TuneConfig(num_samples=2, metric=metric, mode=\"min\"),  # <3>\n",
    ")\n",
    "result_grid = tuner.fit()  # <4>\n",
    "\n",
    "best_result = result_grid.get_best_result()\n",
    "print(\"Best Result:\", best_result)\n",
    "# end::tuner[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598890b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::checkpoint[]\n",
    "checkpoint = best_result.checkpoint\n",
    "print(checkpoint)\n",
    "# end::checkpoint[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302102ed",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::keras_checkpoint[]\n",
    "from ray.train.tensorflow import TensorflowCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "keras_checkpoint = TensorflowCheckpoint.from_model(model)\n",
    "# end::keras_checkpoint[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c0364",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::predictor[]\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "\n",
    "checkpoint = best_result.checkpoint\n",
    "batch_predictor = BatchPredictor.from_checkpoint(checkpoint, XGBoostPredictor)  # <1>\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(test_dataset)  # <2>\n",
    "predicted_probabilities.show()\n",
    "# end::predictor[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b781908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::deployment[]\n",
    "from ray import serve\n",
    "from fastapi import Request\n",
    "import pandas as pd\n",
    "from ray.serve import PredictorDeployment\n",
    "\n",
    "\n",
    "async def adapter(request: Request):  # <1>\n",
    "    payload = await request.json()\n",
    "    return pd.DataFrame.from_dict(payload)\n",
    "\n",
    "\n",
    "serve.start(detached=True)\n",
    "deployment = PredictorDeployment.options(name=\"XGBoostService\")  # <2>\n",
    "\n",
    "deployment.deploy(  # <3>\n",
    "    XGBoostPredictor,\n",
    "    checkpoint,\n",
    "    http_adapter=adapter\n",
    ")\n",
    "\n",
    "print(deployment.url)\n",
    "# end::deployment[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55052dd1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::request[]\n",
    "import requests\n",
    "\n",
    "first_item = test_dataset.take(1)\n",
    "sample_input = dict(first_item[0])\n",
    "\n",
    "result = requests.post(  # <1>\n",
    "    deployment.url,\n",
    "    json=[sample_input]\n",
    ")\n",
    "print(result.json())\n",
    "\n",
    "serve.shutdown()  # <2>\n",
    "# end::request[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956dc58",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::rl_trainer[]\n",
    "from ray.tune.tuner import Tuner\n",
    "from ray.train.rl.rl_trainer import RLTrainer\n",
    "from ray.air.config import RunConfig, ScalingConfig\n",
    "\n",
    "\n",
    "trainer = RLTrainer(  # <1>\n",
    "    run_config=RunConfig(stop={\"training_iteration\": 5}),\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=False),\n",
    "    algorithm=\"PPO\",\n",
    "    config={\"env\": \"CartPole-v0\"},\n",
    ")\n",
    "\n",
    "tuner = Tuner(  # <2>\n",
    "    trainer,\n",
    "    _tuner_kwargs={\"checkpoint_at_end\": True},\n",
    ")\n",
    "\n",
    "result = tuner.fit()[0]  # <3>\n",
    "# end::rl_trainer[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d9922",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::serve_rl_model[]\n",
    "from ray.train.rl.rl_predictor import RLPredictor\n",
    "from ray.serve import PredictorDeployment\n",
    "\n",
    "\n",
    "serve.start(detached=True)\n",
    "deployment = PredictorDeployment.options(name=\"RLDeployment\")\n",
    "deployment.deploy(RLPredictor, result.checkpoint)\n",
    "\n",
    "# end::serve_rl_model[]\n",
    "\n",
    "# serve.run(\n",
    "#     PredictorDeployment.options(name=\"RLDeployment\").bind(RLPredictor, result.checkpoint)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fabd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::use_rl_endpoint[]\n",
    "\n",
    "import gym\n",
    "import requests\n",
    "\n",
    "\n",
    "num_episodes = 5\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "rewards = []\n",
    "for i in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    reward = 0.0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = requests.post(  # <1>\n",
    "            deployment.url,\n",
    "            json={\"array\": obs.tolist()}\n",
    "        ).json()\n",
    "        obs, rew, done, _ = env.step(action)\n",
    "        reward += rew\n",
    "    rewards.append(reward)\n",
    "\n",
    "print(\"Episode rewards:\", rewards)\n",
    "\n",
    "serve.shutdown()\n",
    "# end::use_rl_endpoint[]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
